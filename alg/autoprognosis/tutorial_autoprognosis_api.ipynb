{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoPrognosis API Tutorial\n",
    "\n",
    "A demonstration for AP functionality and operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to use [Autoprognosis](https://arxiv.org/abs/1802.07207). We are using the UCI Spam dataset.\n",
    "\n",
    "See [installation instructions](../../doc/install.md) to install the dependencies.\n",
    "\n",
    "Load dataset and show the first five samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mojgan/opt/anaconda3/envs/mlEnv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import initpath_ap\n",
    "initpath_ap.init_sys_path()\n",
    "import utilmlab\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#df = load_breast_cancer()\n",
    "#X_ = pd.DataFrame(df.data)\n",
    "#Y_ = pd.DataFrame(df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_= pd.read_feather('cardio_data/trained_df_noNan')\n",
    "X_.set_index('eid', inplace=True)\n",
    "Y_= pd.read_feather('cardio_data/trained_df_noNan_outcome')\n",
    "Y_.set_index('eid', inplace=True)\n",
    "#Y_=Y_['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make the data small\n",
    "df_all= X_.join(Y_)\n",
    "df_all=df_all.reindex(np.random.permutation(df_all.index))\n",
    "df_all=df_all[:20000]\n",
    "#df_all.to_csv('cardio_data/small_cardio_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all= df_all[['gender', 'age-0', 'average-sys-0', 'history-of-diabetes', 'hypertention-medication-0', 'smoker',\n",
    "                'average-BMI-0', 'outcome']]\n",
    "#df_all.to_csv('cardio_data/small_cardio_data_7_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_= df_all.drop(columns=['outcome'])\n",
    "Y_= df_all[['outcome']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the AutoPrognosis library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model with few iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = 'aucprc'\n",
    "acquisition_type = 'MPI' # default and prefered is LCB but this generates excessive warnings, MPI is a good compromise.\n",
    "#I changed kernel_freq=100 and Gibbs_iter=100\n",
    "AP_mdl   = model.AutoPrognosis_Classifier(\n",
    "    metric=metric, CV=5, num_iter=3, kernel_freq=10, ensemble=False,\n",
    "    ensemble_size=3, Gibbs_iter=100, burn_in=50, num_components=3, \n",
    "    acquisition_type=acquisition_type, is_nan=False, use_imputer=False, use_preprocessor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: missForest\n",
      "\n",
      "R[write to console]: Loading required package: randomForest\n",
      "\n",
      "R[write to console]: randomForest 4.6-14\n",
      "\n",
      "R[write to console]: Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "R[write to console]: Loading required package: foreach\n",
      "\n",
      "R[write to console]: Loading required package: itertools\n",
      "\n",
      "R[write to console]: Loading required package: iterators\n",
      "\n",
      "R[write to console]: Loading required package: softImpute\n",
      "\n",
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: Loaded softImpute 1.4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ LinearSVM ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56673d36b6e040f2892e3d3eb113090b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ NeuralNet ]\n",
      "[ MultinomialNaiveBayes ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 43s (43s) (129s), Current pipelines:  [[[ NeuralNet ]]], [[[ MultinomialNaiveBayes ]]], [[[ DecisionTrees ]]], BO objective: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ DecisionTrees ]\n",
      "[ Gradient Boosting ]\n",
      "[ AdaBoost ]\n",
      "[ LDA ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 90s (45s) (135s), Current pipelines:  [[[ Gradient Boosting ]]], [[[ AdaBoost ]]], [[[ LDA ]]], BO objective: -1.0000000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ XGBoost ]\n",
      "[ Bagging ]\n",
      "[ LDA ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 3 146s (49s) (146s), Current pipelines:  [[[ XGBoost ]]], [[[ Bagging ]]], [[[ LDA ]]], BO objective: -1.4142135623730951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ LDA ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'initial', 'aucprc': 0.057172614799005705},\n",
       " {'aucprc': 0.042970511167461346,\n",
       "  'aucroc': 0.6587761425272423,\n",
       "  'name': '[ NeuralNet ]',\n",
       "  'cv': 5,\n",
       "  'iter': 0,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'NeuralNet',\n",
       "    'hyperparameters': {'model': \"MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\\n       hidden_layer_sizes=(50, 50), learning_rate='constant',\\n       learning_rate_init=0.001, max_iter=200, momentum=0.9,\\n       nesterovs_momentum=True, power_t=0.5, random_state=None,\\n       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\\n       verbose=False, warm_start=False)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a25fe9550>'},\n",
       " {'aucprc': 0.026046956029114793,\n",
       "  'aucroc': 0.48341496651951343,\n",
       "  'name': '[ MultinomialNaiveBayes ]',\n",
       "  'cv': 5,\n",
       "  'iter': 0,\n",
       "  'component_idx': 1,\n",
       "  'hyperparameter_properties': [{'name': 'MultinomialNaiveBayes',\n",
       "    'hyperparameters': {'model': 'MultinomialNB(alpha=3.385277405518578, class_prior=None, fit_prior=True)'}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a25fdaf10>'},\n",
       " {'aucprc': 0.0,\n",
       "  'aucroc': 0.5,\n",
       "  'name': '[ DecisionTrees ]',\n",
       "  'cv': 5,\n",
       "  'iter': 0,\n",
       "  'component_idx': 2,\n",
       "  'hyperparameter_properties': [{'name': 'DecisionTrees',\n",
       "    'hyperparameters': {'model': \"DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\\n            max_features=None, max_leaf_nodes=None,\\n            min_impurity_decrease=0.0, min_impurity_split=None,\\n            min_samples_leaf=1, min_samples_split=2,\\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\\n            splitter='best')\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a25ff2610>'},\n",
       " {'aucprc': 0.05638328870905825,\n",
       "  'aucroc': 0.6762716383996976,\n",
       "  'name': '[ Gradient Boosting ]',\n",
       "  'cv': 5,\n",
       "  'iter': 1,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "    'hyperparameters': {'model': \"GradientBoostingClassifier(criterion='friedman_mse', init=None,\\n              learning_rate=0.28105633052522483, loss='deviance',\\n              max_depth=2, max_features=None, max_leaf_nodes=None,\\n              min_impurity_decrease=0.0, min_impurity_split=None,\\n              min_samples_leaf=1, min_samples_split=2,\\n              min_weight_fraction_leaf=0.0, n_estimators=225,\\n              presort='auto', random_state=None, subsample=1.0, verbose=0,\\n              warm_start=False)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fba1f90>'},\n",
       " {'aucprc': 0.027890024965213433,\n",
       "  'aucroc': 0.5283823992040986,\n",
       "  'name': '[ AdaBoost ]',\n",
       "  'cv': 5,\n",
       "  'iter': 1,\n",
       "  'component_idx': 1,\n",
       "  'hyperparameter_properties': [{'name': 'AdaBoost',\n",
       "    'hyperparameters': {'model': \"AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\\n          learning_rate=2.962420135668186, n_estimators=2305,\\n          random_state=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a26093510>'},\n",
       " {'aucprc': 0.0624852889618833,\n",
       "  'aucroc': 0.7249708599993299,\n",
       "  'name': '[ LDA ]',\n",
       "  'cv': 5,\n",
       "  'iter': 1,\n",
       "  'component_idx': 2,\n",
       "  'hyperparameter_properties': [{'name': 'LDA',\n",
       "    'hyperparameters': {'model': \"LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\\n              solver='svd', store_covariance=False, tol=0.0001)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fdca490>'},\n",
       " {'aucprc': 0.048220983902074646,\n",
       "  'aucroc': 0.646021813710327,\n",
       "  'name': '[ XGBoost ]',\n",
       "  'cv': 5,\n",
       "  'iter': 2,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n       colsample_bynode=None, colsample_bytree=None, gamma=None,\\n       gpu_id=None, importance_type='gain', interaction_constraints=None,\\n       learning_rate=0.3691106981794623, max_delta_step=None, max_depth=5,\\n       min_child_weight=None, missing=nan, monotone_constraints=None,\\n       n_estimators=141, n_jobs=None, num_parallel_tree=None,\\n       objective='binary:logistic', random_state=None, reg_alpha=None,\\n       reg_lambda=None, scale_pos_weight=None, subsample=None,\\n       tree_method=None, validate_parameters=False, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fba1810>'},\n",
       " {'aucprc': 0.0572083668943544,\n",
       "  'aucroc': 0.6903383216422755,\n",
       "  'name': '[ Bagging ]',\n",
       "  'cv': 5,\n",
       "  'iter': 2,\n",
       "  'component_idx': 1,\n",
       "  'hyperparameter_properties': [{'name': 'Bagging',\n",
       "    'hyperparameters': {'model': 'BaggingClassifier(base_estimator=None, bootstrap=True,\\n         bootstrap_features=False, max_features=1.0,\\n         max_samples=0.1438421943852849, n_estimators=943, n_jobs=1,\\n         oob_score=False, random_state=None, verbose=0, warm_start=False)'}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fccca50>'},\n",
       " {'aucprc': 0.0624852889618833,\n",
       "  'aucroc': 0.7249708599993299,\n",
       "  'name': '[ LDA ]',\n",
       "  'cv': 5,\n",
       "  'iter': 2,\n",
       "  'component_idx': 2,\n",
       "  'hyperparameter_properties': [{'name': 'LDA',\n",
       "    'hyperparameters': {'model': \"LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\\n              solver='svd', store_covariance=False, tol=0.0001)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fdfce10>'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.fit(X_, Y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ~~~First element in the output is the predictions of a single model, the second element is the prediction of the ensemble~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.98759929, 0.01240071],\n",
       "        [0.9912874 , 0.0087126 ],\n",
       "        [0.96629033, 0.03370967],\n",
       "        ...,\n",
       "        [0.95964161, 0.04035839],\n",
       "        [0.96429803, 0.03570197],\n",
       "        [0.98756443, 0.01243557]]),\n",
       " array([[0.98759929, 0.01240071],\n",
       "        [0.9912874 , 0.0087126 ],\n",
       "        [0.96629033, 0.03370967],\n",
       "        ...,\n",
       "        [0.95964161, 0.04035839],\n",
       "        [0.96429803, 0.03570197],\n",
       "        [0.98756443, 0.01243557]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.predict(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute performance via multi-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: missForest\n",
      "\n",
      "R[write to console]: Loading required package: randomForest\n",
      "\n",
      "R[write to console]: randomForest 4.6-14\n",
      "\n",
      "R[write to console]: Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "R[write to console]: Loading required package: foreach\n",
      "\n",
      "R[write to console]: Loading required package: itertools\n",
      "\n",
      "R[write to console]: Loading required package: iterators\n",
      "\n",
      "R[write to console]: Loading required package: softImpute\n",
      "\n",
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: Loaded softImpute 1.4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ LinearSVM ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2715cc82f146d380ed69b949116fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ XGBoost ]\n",
      "[ BernoullinNaiveBayes ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 14s (14s) (41s), Current pipelines:  [[[ XGBoost ]]], [[[ BernoullinNaiveBayes ]]], [[[ DecisionTrees ]]], BO objective: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ DecisionTrees ]\n",
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ KNN ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 40s (20s) (60s), Current pipelines:  [[[ Gradient Boosting ]]], [[[ MultinomialNaiveBayes ]]], [[[ KNN ]]], BO objective: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ NeuralNet ]\n",
      "[ BernoullinNaiveBayes ]\n",
      "[ KNN ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 3 59s (20s) (59s), Current pipelines:  [[[ NeuralNet ]]], [[[ BernoullinNaiveBayes ]]], [[[ KNN ]]], BO objective: -1.4142135623730947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ Gradient Boosting ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'AutoPrognosis_Classifier' object has no attribute 'ensemble_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a5722016460e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_ens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAP_mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/University/UKBioBank/AutoPrognosis-master/alg/autoprognosis/model.py\u001b[0m in \u001b[0;36mevaluate_ens\u001b[0;34m(X, Y, model_input, n_folds, visualize)\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0;31m#preds_ens        = model.predict(X_test)[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0mpreds_ens\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mpredict_ens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0;31m# metric_[indx]     = roc_auc_score(Y_test, preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoPrognosis_Classifier' object has no attribute 'ensemble_models'"
     ]
    }
   ],
   "source": [
    "model.evaluate_ens(X_, Y_, AP_mdl, n_folds=5, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a37862d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.visualize_data(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\r",
       "***Ensemble Report***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank0:   [ XGBoost ],   Ensemble weight: 0.337141036259983**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.classifiers.XGboost object at 0x1a3466ae90>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank1:   [ AdaBoost ],   Ensemble weight: 0.33191778877869144**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.classifiers.Adaboost object at 0x1a34668790>], 'explained': \"[ *AdaBoost, short for Adaptive Boosting, is a machine learning meta-algorithm formulated by Yoav Freund and Robert Schapire, who won the 2003 Gödel Prize for their work. It can be used in conjunction with many other types of learning algorithms to improve performance. The output of the other learning algorithms ('weak learners') is combined into a weighted sum that represents the final output of the boosted classifier. AdaBoost is adaptive in the sense that subsequent weak learners are tweaked in favor of those instances misclassified by previous classifiers.* ]\", 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ AdaBoost ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ *AdaBoost, short for Adaptive Boosting, is a machine learning meta-algorithm formulated by Yoav Freund and Robert Schapire, who won the 2003 Gödel Prize for their work. It can be used in conjunction with many other types of learning algorithms to improve performance. The output of the other learning algorithms ('weak learners') is combined into a weighted sum that represents the final output of the boosted classifier. AdaBoost is adaptive in the sense that subsequent weak learners are tweaked in favor of those instances misclassified by previous classifiers.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank2:   [ XGBoost ],   Ensemble weight: 0.33094117496132563**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.classifiers.XGboost object at 0x1a376f1e90>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "***Kernel Report***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['XGBoost', 'Gradient Boosting', 'Random Forest', 'Neural Network']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mMat52.     \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |  0.9999990030869095  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  0.9031481051397683  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 1**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['Multinomial Naive Bayes', 'Bernoulli Naive Bayes', 'Bagging', 'Adaboost']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mMat52.     \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |  0.9720888366936934  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |   5.127609133763431  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 2**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['Linear SVM', 'KNN', 'Decision Trees', 'Perceptron', 'Logistic Regression', 'Gauss Naive Bayes', 'QDA', 'LDA']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mMat52.     \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |   46.03231114719721  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  21.029530765403038  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_score_single_pipeline': 0.06294085111764766,\n",
       " 'model_names_single_pipeline': '[ XGBoost ]',\n",
       " 'ensemble_score': 0.06402736930011581,\n",
       " 'ensemble_pipelines': ['[ XGBoost ]', '[ AdaBoost ]', '[ XGBoost ]'],\n",
       " 'ensemble_pipelines_weight': [0.337141036259983,\n",
       "  0.33191778877869144,\n",
       "  0.33094117496132563],\n",
       " 'optimisation_metric': 'aucprc',\n",
       " 'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "   'hyperparameters': {'model': \"XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\\n       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\\n       importance_type='gain', interaction_constraints=None,\\n       learning_rate=0.06145542076570746, max_delta_step=0, max_depth=2,\\n       min_child_weight=1, missing=nan, monotone_constraints=None,\\n       n_estimators=253, n_jobs=0, num_parallel_tree=1,\\n       objective='binary:logistic', random_state=0, reg_alpha=0,\\n       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\\n       validate_parameters=False, verbosity=None)\"}}],\n",
       " 'acquisition_type': 'MPI',\n",
       " 'kernel_members': {0: ['XGBoost',\n",
       "   'Gradient Boosting',\n",
       "   'Random Forest',\n",
       "   'Neural Network'],\n",
       "  1: ['Multinomial Naive Bayes',\n",
       "   'Bernoulli Naive Bayes',\n",
       "   'Bagging',\n",
       "   'Adaboost'],\n",
       "  2: ['Linear SVM',\n",
       "   'KNN',\n",
       "   'Decision Trees',\n",
       "   'Perceptron',\n",
       "   'Logistic Regression',\n",
       "   'Gauss Naive Bayes',\n",
       "   'QDA',\n",
       "   'LDA']}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.APReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "state": {
    "b36d11ca14b24a118b3c3a295a788faf": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
