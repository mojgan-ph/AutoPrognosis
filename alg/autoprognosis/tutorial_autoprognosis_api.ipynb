{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoPrognosis API Tutorial\n",
    "\n",
    "A demonstration for AP functionality and operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to use [Autoprognosis](https://arxiv.org/abs/1802.07207). We are using the UCI Spam dataset.\n",
    "\n",
    "See [installation instructions](../../doc/install.md) to install the dependencies.\n",
    "\n",
    "Load dataset and show the first five samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mojgan/opt/anaconda3/envs/mlEnv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import initpath_ap\n",
    "initpath_ap.init_sys_path()\n",
    "import utilmlab\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#df = load_breast_cancer()\n",
    "#X_ = pd.DataFrame(df.data)\n",
    "#Y_ = pd.DataFrame(df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the AutoPrognosis library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--it : total number of iterations for each fold or n-fold cross validation\n",
    "\n",
    "--cv : n for n-fold cross validation\n",
    "\n",
    "--nstage: size of pipeline: 0: auto (selects imputation when missing data is detected),\n",
    "        1: only classifiers, \n",
    "        2: feature processesing + clf, \n",
    "        3: imputers + feature processors and clf\n",
    "        \n",
    "--ensemble : include ensembles when fitting. It gives an assertion error when set to 0! should be looked into.\n",
    "\n",
    "--modelindexes : list of \n",
    "\n",
    "0 Random Forest,\n",
    "1 Gradient Boosting, \n",
    "2 XGBoost, \n",
    "3 Adaboost, \n",
    "4 Bagging, \n",
    "5 Bernoulli Naive Bayes, \n",
    "6 Gauss Naive Bayes, \n",
    "7 Multinomial Naive Bayes, \n",
    "8 Logistic Regression, \n",
    "9 Perceptron, \n",
    "10 Decision Trees, \n",
    "11 QDA, \n",
    "12 LDA, \n",
    "13 KNN, \n",
    "14 Linear SVM, \n",
    "15 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: missForest\n",
      "\n",
      "R[write to console]: Loading required package: randomForest\n",
      "\n",
      "R[write to console]: randomForest 4.6-14\n",
      "\n",
      "R[write to console]: Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "R[write to console]: Loading required package: foreach\n",
      "\n",
      "R[write to console]: Loading required package: itertools\n",
      "\n",
      "R[write to console]: Loading required package: iterators\n",
      "\n",
      "R[write to console]: Loading required package: softImpute\n",
      "\n",
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: Loaded softImpute 1.4\n",
      "\n",
      "\n",
      "[ Random Forest ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=50.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ Random Forest ]\n",
      "Iteration number: 1 11s (11s) (565s), Current pipelines:  [[[ Random Forest ]]], BO objective: 0.0\n",
      "[ Random Forest ]\n",
      "Iteration number: 2 16s (8s) (391s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0000000000000024\n",
      "[ Random Forest ]\n",
      "Iteration number: 3 18s (6s) (294s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1693985546594983\n",
      "[ Random Forest ]\n",
      "Iteration number: 4 20s (5s) (246s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9735546461776603\n",
      "[ Random Forest ]\n",
      "Iteration number: 5 22s (4s) (217s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1163846123124266\n",
      "[ Random Forest ]\n",
      "Iteration number: 6 24s (4s) (199s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.053816893957602\n",
      "[ Random Forest ]\n",
      "Iteration number: 7 26s (4s) (185s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0449178651422746\n",
      "[ Random Forest ]\n",
      "Iteration number: 8 28s (4s) (177s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9378156727712538\n",
      "[ Random Forest ]\n",
      "Iteration number: 9 30s (3s) (169s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9629272036943446\n",
      "[ Random Forest ]\n",
      "Iteration number: 10 32s (3s) (162s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0104462610106417\n",
      "[ Random Forest ]\n",
      "Iteration number: 11 34s (3s) (156s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9549853283994914\n",
      "[ Random Forest ]\n",
      "Iteration number: 12 36s (3s) (151s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9860306011790895\n",
      "[ Random Forest ]\n",
      "Iteration number: 13 38s (3s) (147s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9233249068761881\n",
      "[ Random Forest ]\n",
      "Iteration number: 14 40s (3s) (144s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9882097780540565\n",
      "[ Random Forest ]\n",
      "Iteration number: 15 42s (3s) (141s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9282503812704485\n",
      "[ Random Forest ]\n",
      "Iteration number: 16 45s (3s) (139s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0189103726509308\n",
      "[ Random Forest ]\n",
      "Iteration number: 17 46s (3s) (136s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9972240815073522\n",
      "[ Random Forest ]\n",
      "Iteration number: 18 48s (3s) (134s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.027199688164528\n",
      "[ Random Forest ]\n",
      "Iteration number: 19 50s (3s) (133s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9982580415041241\n",
      "[ Random Forest ]\n",
      "Iteration number: 20 53s (3s) (131s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9822876484156264\n",
      "[ Random Forest ]\n",
      "Iteration number: 21 55s (3s) (130s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9801290578913372\n",
      "[ Random Forest ]\n",
      "Iteration number: 22 57s (3s) (129s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.97890099956992\n",
      "[ Random Forest ]\n",
      "Iteration number: 23 59s (3s) (127s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9920102233629575\n",
      "[ Random Forest ]\n",
      "Iteration number: 24 61s (3s) (127s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9578399975300174\n",
      "[ Random Forest ]\n",
      "Iteration number: 25 63s (3s) (127s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0766496281774232\n",
      "[ Random Forest ]\n",
      "Iteration number: 26 66s (3s) (127s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0392019906539354\n",
      "[ Random Forest ]\n",
      "Iteration number: 27 68s (3s) (126s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0223913902267452\n",
      "[ Random Forest ]\n",
      "Iteration number: 28 71s (3s) (126s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.990125127030431\n",
      "[ Random Forest ]\n",
      "Iteration number: 29 73s (3s) (127s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9611825422633744\n",
      "[ Random Forest ]\n",
      "Iteration number: 30 76s (3s) (127s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9572281660932882\n",
      "[ Random Forest ]\n",
      "Iteration number: 31 79s (3s) (127s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.933631924410861\n",
      "[ Random Forest ]\n",
      "Iteration number: 32 82s (3s) (129s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9493249275306933\n",
      "[ Random Forest ]\n",
      "Iteration number: 33 85s (3s) (129s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9466388303546275\n",
      "[ Random Forest ]\n",
      "Iteration number: 34 87s (3s) (129s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9504928520686371\n",
      "[ Random Forest ]\n",
      "Iteration number: 35 90s (3s) (128s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9387862323175565\n",
      "[ Random Forest ]\n",
      "Iteration number: 36 92s (3s) (128s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9397030772930824\n",
      "[ Random Forest ]\n",
      "Iteration number: 37 95s (3s) (129s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9398457388505947\n",
      "[ Random Forest ]\n",
      "Iteration number: 38 98s (3s) (129s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9502642384149691\n",
      "[ Random Forest ]\n",
      "Iteration number: 39 101s (3s) (130s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9462037887058518\n",
      "[ Random Forest ]\n",
      "Iteration number: 40 104s (3s) (130s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9377784195322064\n",
      "[ Random Forest ]\n",
      "Iteration number: 41 108s (3s) (132s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9457863563422897\n",
      "[ Random Forest ]\n",
      "Iteration number: 42 112s (3s) (133s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9559431627495585\n",
      "[ Random Forest ]\n",
      "Iteration number: 43 115s (3s) (133s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9626641942746951\n",
      "[ Random Forest ]\n",
      "Iteration number: 44 117s (3s) (133s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9517658394175031\n",
      "[ Random Forest ]\n",
      "Iteration number: 45 121s (3s) (134s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9362838337949765\n",
      "[ Random Forest ]\n",
      "Iteration number: 46 124s (3s) (135s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9378051265358076\n",
      "[ Random Forest ]\n",
      "Iteration number: 47 128s (3s) (136s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9560602524895462\n",
      "[ Random Forest ]\n",
      "Iteration number: 48 135s (3s) (141s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9443424898807088\n",
      "[ Random Forest ]\n",
      "Iteration number: 49 138s (3s) (141s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9495389273156923\n",
      "[ Random Forest ]\n",
      "Iteration number: 50 143s (3s) (143s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9526236337194084\n",
      "\n",
      "[ Random Forest ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=50.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ Random Forest ]\n",
      "Iteration number: 1 2s (2s) (75s), Current pipelines:  [[[ Random Forest ]]], BO objective: 0.0\n",
      "[ Random Forest ]\n",
      "Iteration number: 2 3s (2s) (85s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0000000000000069\n",
      "[ Random Forest ]\n",
      "Iteration number: 3 6s (2s) (94s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3893268115965074\n",
      "[ Random Forest ]\n",
      "Iteration number: 4 8s (2s) (101s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0960830520519145\n",
      "[ Random Forest ]\n",
      "Iteration number: 5 10s (2s) (103s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.323383394817786\n",
      "[ Random Forest ]\n",
      "Iteration number: 6 13s (2s) (106s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.7526577185236178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "Iteration number: 7 15s (2s) (107s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3610524165751818\n",
      "[ Random Forest ]\n",
      "Iteration number: 8 17s (2s) (108s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2010444814680903\n",
      "[ Random Forest ]\n",
      "Iteration number: 9 20s (2s) (110s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1386477059854492\n",
      "[ Random Forest ]\n",
      "Iteration number: 10 22s (2s) (110s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.168409833569713\n",
      "[ Random Forest ]\n",
      "Iteration number: 11 24s (2s) (111s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1084714440473036\n",
      "[ Random Forest ]\n",
      "Iteration number: 12 27s (2s) (112s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0704510084650891\n",
      "[ Random Forest ]\n",
      "Iteration number: 13 30s (2s) (114s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1147572912247323\n",
      "[ Random Forest ]\n",
      "Iteration number: 14 32s (2s) (114s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0542380674358767\n",
      "[ Random Forest ]\n",
      "Iteration number: 15 35s (2s) (116s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2038945139905035\n",
      "[ Random Forest ]\n",
      "Iteration number: 16 39s (2s) (123s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2336557762576688\n",
      "[ Random Forest ]\n",
      "Iteration number: 17 42s (2s) (122s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2526465637916255\n",
      "[ Random Forest ]\n",
      "Iteration number: 18 44s (2s) (122s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2121726856046795\n",
      "[ Random Forest ]\n",
      "Iteration number: 19 46s (2s) (122s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2242010444821458\n",
      "[ Random Forest ]\n",
      "Iteration number: 20 49s (2s) (122s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1936083147068624\n",
      "[ Random Forest ]\n",
      "Iteration number: 21 51s (2s) (121s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1577280604454623\n",
      "[ Random Forest ]\n",
      "Iteration number: 22 53s (2s) (121s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1355561354768586\n",
      "[ Random Forest ]\n",
      "Iteration number: 23 56s (2s) (121s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.14690496910642\n",
      "[ Random Forest ]\n",
      "Iteration number: 24 58s (2s) (121s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.174799985990726\n",
      "[ Random Forest ]\n",
      "Iteration number: 25 60s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1984060430277426\n",
      "[ Random Forest ]\n",
      "Iteration number: 26 62s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2244615070282743\n",
      "[ Random Forest ]\n",
      "Iteration number: 27 65s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1806699672636187\n",
      "[ Random Forest ]\n",
      "Iteration number: 28 67s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2045764301893764\n",
      "[ Random Forest ]\n",
      "Iteration number: 29 69s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2169884868148042\n",
      "[ Random Forest ]\n",
      "Iteration number: 30 72s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1879442962376583\n",
      "[ Random Forest ]\n",
      "Iteration number: 31 74s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1935389543075647\n",
      "[ Random Forest ]\n",
      "Iteration number: 32 77s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.36873386355373\n",
      "[ Random Forest ]\n",
      "Iteration number: 33 79s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3829432437050018\n",
      "[ Random Forest ]\n",
      "Iteration number: 34 82s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.397477216455549\n",
      "[ Random Forest ]\n",
      "Iteration number: 35 84s (2s) (119s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4224296952155866\n",
      "[ Random Forest ]\n",
      "Iteration number: 36 86s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4362278898090377\n",
      "[ Random Forest ]\n",
      "Iteration number: 37 89s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4491225075660528\n",
      "[ Random Forest ]\n",
      "Iteration number: 38 92s (2s) (120s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4613266411407098\n",
      "[ Random Forest ]\n",
      "Iteration number: 39 95s (2s) (121s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.440928130756831\n",
      "[ Random Forest ]\n",
      "Iteration number: 40 97s (2s) (122s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4147472237089505\n",
      "[ Random Forest ]\n",
      "Iteration number: 41 101s (2s) (123s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4260796133682714\n",
      "[ Random Forest ]\n",
      "Iteration number: 42 104s (2s) (124s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3907472871608142\n",
      "[ Random Forest ]\n",
      "Iteration number: 43 107s (2s) (125s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.7117715244349097\n",
      "[ Random Forest ]\n",
      "Iteration number: 44 110s (3s) (125s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6878948411218313\n",
      "[ Random Forest ]\n",
      "Iteration number: 45 114s (3s) (126s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6480936629380127\n",
      "[ Random Forest ]\n",
      "Iteration number: 46 118s (3s) (128s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6321656589031395\n",
      "[ Random Forest ]\n",
      "Iteration number: 47 121s (3s) (129s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6133949829805996\n",
      "[ Random Forest ]\n",
      "Iteration number: 48 124s (3s) (130s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5914452130324923\n",
      "[ Random Forest ]\n",
      "Iteration number: 49 128s (3s) (130s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.590864014922789\n",
      "[ Random Forest ]\n",
      "Iteration number: 50 131s (3s) (131s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5533696049681045\n",
      "\n",
      "[ Random Forest ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=50.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ Random Forest ]\n",
      "Iteration number: 1 10s (10s) (511s), Current pipelines:  [[[ Random Forest ]]], BO objective: 0.0\n",
      "[ Random Forest ]\n",
      "Iteration number: 2 23s (11s) (575s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9999999999999928\n",
      "[ Random Forest ]\n",
      "Iteration number: 3 35s (12s) (582s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9682333249297665\n",
      "[ Random Forest ]\n",
      "Iteration number: 4 45s (11s) (556s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.999026514114038\n",
      "[ Random Forest ]\n",
      "Iteration number: 5 56s (11s) (557s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0735142510538507\n",
      "[ Random Forest ]\n",
      "Iteration number: 6 71s (12s) (594s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0406829230443078\n",
      "[ Random Forest ]\n",
      "Iteration number: 7 88s (13s) (632s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9578904660727191\n",
      "[ Random Forest ]\n",
      "Iteration number: 8 96s (12s) (602s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.074530875254351\n",
      "[ Random Forest ]\n",
      "Iteration number: 9 101s (11s) (560s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.009273294478627\n",
      "[ Random Forest ]\n",
      "Iteration number: 10 107s (11s) (537s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.702172890591521\n",
      "[ Random Forest ]\n",
      "Iteration number: 11 113s (10s) (513s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.8071189914890475\n",
      "[ Random Forest ]\n",
      "Iteration number: 12 118s (10s) (493s), Current pipelines:  [[[ Random Forest ]]], BO objective: -2.234190192702104\n",
      "[ Random Forest ]\n",
      "Iteration number: 13 124s (10s) (477s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.8852255628337067\n",
      "[ Random Forest ]\n",
      "Iteration number: 14 133s (10s) (476s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6456692289163026\n",
      "[ Random Forest ]\n",
      "Iteration number: 15 137s (9s) (457s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.661717788398393\n",
      "[ Random Forest ]\n",
      "Iteration number: 16 142s (9s) (443s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.8059622852182711\n",
      "[ Random Forest ]\n",
      "Iteration number: 17 145s (9s) (427s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.8057525952832852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "Iteration number: 18 148s (8s) (412s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.8056445188850387\n",
      "[ Random Forest ]\n",
      "Iteration number: 19 151s (8s) (396s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.8196282702554122\n",
      "[ Random Forest ]\n",
      "Iteration number: 20 156s (8s) (389s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.8496645678836001\n",
      "[ Random Forest ]\n",
      "Iteration number: 21 161s (8s) (384s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.8662910457109849\n",
      "[ Random Forest ]\n",
      "Iteration number: 22 165s (8s) (375s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.8931856306316193\n",
      "[ Random Forest ]\n",
      "Iteration number: 23 168s (7s) (365s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9024391744967983\n",
      "[ Random Forest ]\n",
      "Iteration number: 24 175s (7s) (364s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9222694112660194\n",
      "[ Random Forest ]\n",
      "Iteration number: 25 178s (7s) (357s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.93428891191853\n",
      "[ Random Forest ]\n",
      "Iteration number: 26 184s (7s) (353s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9409141127145811\n",
      "[ Random Forest ]\n",
      "Iteration number: 27 191s (7s) (354s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9639628364813548\n",
      "[ Random Forest ]\n",
      "Iteration number: 28 211s (8s) (377s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9899329615492432\n",
      "[ Random Forest ]\n",
      "Iteration number: 29 234s (8s) (404s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9963371968941104\n",
      "[ Random Forest ]\n",
      "Iteration number: 30 238s (8s) (397s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0176233315658405\n",
      "[ Random Forest ]\n",
      "Iteration number: 31 265s (9s) (427s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0439448909169085\n",
      "[ Random Forest ]\n",
      "Iteration number: 32 266s (8s) (416s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.044519516425013\n",
      "[ Random Forest ]\n",
      "Iteration number: 33 282s (9s) (427s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0705268683213391\n",
      "[ Random Forest ]\n",
      "Iteration number: 34 298s (9s) (439s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0999456337855462\n",
      "[ Random Forest ]\n",
      "Iteration number: 35 304s (9s) (434s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1016820558437659\n",
      "[ Random Forest ]\n",
      "Iteration number: 36 306s (9s) (426s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.096244305723601\n",
      "[ Random Forest ]\n",
      "Iteration number: 37 332s (9s) (449s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0991970853808404\n",
      "[ Random Forest ]\n",
      "Iteration number: 38 351s (9s) (462s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1166155187245541\n",
      "[ Random Forest ]\n",
      "Iteration number: 39 353s (9s) (452s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1346788819776772\n",
      "[ Random Forest ]\n",
      "Iteration number: 40 365s (9s) (456s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.159970689177682\n",
      "[ Random Forest ]\n",
      "Iteration number: 41 371s (9s) (452s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1838163630196474\n",
      "[ Random Forest ]\n",
      "Iteration number: 42 374s (9s) (446s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2078344802370253\n",
      "[ Random Forest ]\n",
      "Iteration number: 43 377s (9s) (439s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2018118896341163\n",
      "[ Random Forest ]\n",
      "Iteration number: 44 382s (9s) (434s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2006106036995146\n",
      "[ Random Forest ]\n",
      "Iteration number: 45 387s (9s) (429s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1994480086870605\n",
      "[ Random Forest ]\n",
      "Iteration number: 46 390s (8s) (424s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1992570766291624\n",
      "[ Random Forest ]\n",
      "Iteration number: 47 393s (8s) (418s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1900198566452225\n",
      "[ Random Forest ]\n",
      "Iteration number: 48 397s (8s) (413s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.19006678639486\n",
      "[ Random Forest ]\n",
      "Iteration number: 49 400s (8s) (408s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.186549341585778\n",
      "[ Random Forest ]\n",
      "Iteration number: 50 403s (8s) (403s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1923729001191365\n",
      "\n",
      "[ Random Forest ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=50.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ Random Forest ]\n",
      "Iteration number: 1 4s (4s) (187s), Current pipelines:  [[[ Random Forest ]]], BO objective: 0.0\n",
      "[ Random Forest ]\n",
      "Iteration number: 2 7s (3s) (165s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.999999999999966\n",
      "[ Random Forest ]\n",
      "Iteration number: 3 9s (3s) (145s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0946557400432912\n",
      "[ Random Forest ]\n",
      "Iteration number: 4 13s (3s) (166s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2759424681374407\n",
      "[ Random Forest ]\n",
      "Iteration number: 5 17s (3s) (167s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1262179562905297\n",
      "[ Random Forest ]\n",
      "Iteration number: 6 20s (3s) (165s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3093039219557394\n",
      "[ Random Forest ]\n",
      "Iteration number: 7 27s (4s) (193s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3140163025542118\n",
      "[ Random Forest ]\n",
      "Iteration number: 8 30s (4s) (189s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4464297551499208\n",
      "[ Random Forest ]\n",
      "Iteration number: 9 34s (4s) (187s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5074598710471385\n",
      "[ Random Forest ]\n",
      "Iteration number: 10 39s (4s) (196s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5007170050003096\n",
      "[ Random Forest ]\n",
      "Iteration number: 11 55s (5s) (249s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.556323863863149\n",
      "[ Random Forest ]\n",
      "Iteration number: 12 59s (5s) (245s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6093322497832738\n",
      "[ Random Forest ]\n",
      "Iteration number: 13 65s (5s) (252s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6749751879989856\n",
      "[ Random Forest ]\n",
      "Iteration number: 14 75s (5s) (267s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.7199854980270453\n",
      "[ Random Forest ]\n",
      "Iteration number: 15 94s (6s) (314s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5194307089134726\n",
      "[ Random Forest ]\n",
      "Iteration number: 16 106s (7s) (330s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5540852540664012\n",
      "[ Random Forest ]\n",
      "Iteration number: 17 116s (7s) (341s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4317450703497379\n",
      "[ Random Forest ]\n",
      "Iteration number: 18 126s (7s) (351s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4161316241484199\n",
      "[ Random Forest ]\n",
      "Iteration number: 19 136s (7s) (358s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4044906788666176\n",
      "[ Random Forest ]\n",
      "Iteration number: 20 148s (7s) (371s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3949335845049315\n",
      "[ Random Forest ]\n",
      "Iteration number: 21 158s (8s) (376s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4117743287217397\n",
      "[ Random Forest ]\n",
      "Iteration number: 22 168s (8s) (381s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.371301914560204\n",
      "[ Random Forest ]\n",
      "Iteration number: 23 177s (8s) (385s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2925833870011108\n",
      "[ Random Forest ]\n",
      "Iteration number: 24 188s (8s) (391s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2769102343266665\n",
      "[ Random Forest ]\n",
      "Iteration number: 25 198s (8s) (395s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4218493272284538\n",
      "[ Random Forest ]\n",
      "Iteration number: 26 207s (8s) (399s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4084521147225162\n",
      "[ Random Forest ]\n",
      "Iteration number: 27 217s (8s) (402s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3867711033157522\n",
      "[ Random Forest ]\n",
      "Iteration number: 28 227s (8s) (405s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3805935072667244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "Iteration number: 29 235s (8s) (406s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3142603187404214\n",
      "[ Random Forest ]\n",
      "Iteration number: 30 244s (8s) (407s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.286072891783522\n",
      "[ Random Forest ]\n",
      "Iteration number: 31 255s (8s) (411s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2475379520574008\n",
      "[ Random Forest ]\n",
      "Iteration number: 32 263s (8s) (411s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2301943862567595\n",
      "[ Random Forest ]\n",
      "Iteration number: 33 272s (8s) (412s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1939085872938733\n",
      "[ Random Forest ]\n",
      "Iteration number: 34 280s (8s) (412s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1834673841918029\n",
      "[ Random Forest ]\n",
      "Iteration number: 35 289s (8s) (413s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1594781728435424\n",
      "[ Random Forest ]\n",
      "Iteration number: 36 298s (8s) (414s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.133080179647414\n",
      "[ Random Forest ]\n",
      "Iteration number: 37 306s (8s) (414s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1225603805187685\n",
      "[ Random Forest ]\n",
      "Iteration number: 38 315s (8s) (415s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1084118760087358\n",
      "[ Random Forest ]\n",
      "Iteration number: 39 326s (8s) (418s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.413725146655252\n",
      "[ Random Forest ]\n",
      "Iteration number: 40 334s (8s) (418s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.395993791973992\n",
      "[ Random Forest ]\n",
      "Iteration number: 41 341s (8s) (416s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.52859356190268\n",
      "[ Random Forest ]\n",
      "Iteration number: 42 347s (8s) (414s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.773706231096579\n",
      "[ Random Forest ]\n",
      "Iteration number: 43 354s (8s) (412s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.787827134193643\n",
      "[ Random Forest ]\n",
      "Iteration number: 44 361s (8s) (410s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.7547652514019279\n",
      "[ Random Forest ]\n",
      "Iteration number: 45 368s (8s) (409s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.68995323508475\n",
      "[ Random Forest ]\n",
      "Iteration number: 46 374s (8s) (407s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6691135685234628\n",
      "[ Random Forest ]\n",
      "Iteration number: 47 381s (8s) (405s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6203527230072121\n",
      "[ Random Forest ]\n",
      "Iteration number: 48 387s (8s) (404s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5705840373283493\n",
      "[ Random Forest ]\n",
      "Iteration number: 49 394s (8s) (402s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5295840650944845\n",
      "[ Random Forest ]\n",
      "Iteration number: 50 400s (8s) (400s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.6620424433604157\n",
      "\n",
      "[ Random Forest ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=50.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ Random Forest ]\n",
      "Iteration number: 1 2s (2s) (83s), Current pipelines:  [[[ Random Forest ]]], BO objective: 0.0\n",
      "[ Random Forest ]\n",
      "Iteration number: 2 6s (3s) (150s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0000000000000095\n",
      "[ Random Forest ]\n",
      "Iteration number: 3 8s (3s) (134s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3527794926829988\n",
      "[ Random Forest ]\n",
      "Iteration number: 4 10s (3s) (130s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4704135463136023\n",
      "[ Random Forest ]\n",
      "Iteration number: 5 14s (3s) (139s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1854319057576268\n",
      "[ Random Forest ]\n",
      "Iteration number: 6 16s (3s) (136s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3446736871596014\n",
      "[ Random Forest ]\n",
      "Iteration number: 7 19s (3s) (137s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.327908370057423\n",
      "[ Random Forest ]\n",
      "Iteration number: 8 28s (4s) (175s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.4690483008245359\n",
      "[ Random Forest ]\n",
      "Iteration number: 9 53s (6s) (292s), Current pipelines:  [[[ Random Forest ]]], BO objective: -2.080509455989967\n",
      "[ Random Forest ]\n",
      "Iteration number: 10 61s (6s) (307s), Current pipelines:  [[[ Random Forest ]]], BO objective: -2.0675248124310537\n",
      "[ Random Forest ]\n",
      "Iteration number: 11 71s (6s) (322s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.8001826718899503\n",
      "[ Random Forest ]\n",
      "Iteration number: 12 81s (7s) (336s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5895183886666697\n",
      "[ Random Forest ]\n",
      "Iteration number: 13 92s (7s) (356s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.5046455573443123\n",
      "[ Random Forest ]\n",
      "Iteration number: 14 102s (7s) (363s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.46131480933413\n",
      "[ Random Forest ]\n",
      "Iteration number: 15 111s (7s) (371s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3937110885364343\n",
      "[ Random Forest ]\n",
      "Iteration number: 16 121s (8s) (377s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3188529325929896\n",
      "[ Random Forest ]\n",
      "Iteration number: 17 130s (8s) (382s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2720897829439017\n",
      "[ Random Forest ]\n",
      "Iteration number: 18 139s (8s) (386s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.270780423859056\n",
      "[ Random Forest ]\n",
      "Iteration number: 19 150s (8s) (395s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.232707829437835\n",
      "[ Random Forest ]\n",
      "Iteration number: 20 163s (8s) (406s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.2139078241404864\n",
      "[ Random Forest ]\n",
      "Iteration number: 21 175s (8s) (416s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1736077349935803\n",
      "[ Random Forest ]\n",
      "Iteration number: 22 187s (9s) (425s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1360002561064824\n",
      "[ Random Forest ]\n",
      "Iteration number: 23 196s (9s) (427s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1319136780059915\n",
      "[ Random Forest ]\n",
      "Iteration number: 24 205s (9s) (427s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0888417532678931\n",
      "[ Random Forest ]\n",
      "Iteration number: 25 214s (9s) (428s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1364716382495184\n",
      "[ Random Forest ]\n",
      "Iteration number: 26 236s (9s) (455s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.108082703255057\n",
      "[ Random Forest ]\n",
      "Iteration number: 27 247s (9s) (458s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.124256207805277\n",
      "[ Random Forest ]\n",
      "Iteration number: 28 256s (9s) (457s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.110690181607084\n",
      "[ Random Forest ]\n",
      "Iteration number: 29 268s (9s) (461s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0792845605805597\n",
      "[ Random Forest ]\n",
      "Iteration number: 30 276s (9s) (460s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0882230965707456\n",
      "[ Random Forest ]\n",
      "Iteration number: 31 286s (9s) (461s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0628609632631532\n",
      "[ Random Forest ]\n",
      "Iteration number: 32 298s (9s) (466s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.039723445336017\n",
      "[ Random Forest ]\n",
      "Iteration number: 33 307s (9s) (465s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0696372041308655\n",
      "[ Random Forest ]\n",
      "Iteration number: 34 322s (9s) (474s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3845332643682036\n",
      "[ Random Forest ]\n",
      "Iteration number: 35 335s (10s) (479s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.3754448477145547\n",
      "[ Random Forest ]\n",
      "Iteration number: 36 346s (10s) (480s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.355297364846552\n",
      "[ Random Forest ]\n",
      "Iteration number: 37 358s (10s) (483s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.326366661772293\n",
      "[ Random Forest ]\n",
      "Iteration number: 38 366s (10s) (481s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1420890649675774\n",
      "[ Random Forest ]\n",
      "Iteration number: 39 374s (10s) (479s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1247159514761944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "Iteration number: 40 382s (10s) (477s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.1041072140902224\n",
      "[ Random Forest ]\n",
      "Iteration number: 41 390s (10s) (475s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0956257910797689\n",
      "[ Random Forest ]\n",
      "Iteration number: 42 398s (9s) (473s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0789502457322062\n",
      "[ Random Forest ]\n",
      "Iteration number: 43 406s (9s) (472s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0663531281924863\n",
      "[ Random Forest ]\n",
      "Iteration number: 44 414s (9s) (470s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0595026821448361\n",
      "[ Random Forest ]\n",
      "Iteration number: 45 422s (9s) (469s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0516253207686272\n",
      "[ Random Forest ]\n",
      "Iteration number: 46 430s (9s) (468s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0343702871179021\n",
      "[ Random Forest ]\n",
      "Iteration number: 47 438s (9s) (466s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0300285765310242\n",
      "[ Random Forest ]\n",
      "Iteration number: 48 446s (9s) (465s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0173685519405382\n",
      "[ Random Forest ]\n",
      "Iteration number: 49 455s (9s) (464s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0037977456672877\n",
      "[ Random Forest ]\n",
      "Iteration number: 50 463s (9s) (463s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9894680713315729\n",
      "\n",
      "{'model_list': [<models.classifiers.RandomForest object at 0x1a256c19d0>], 'explained': '[ *Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ Random Forest ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.RandomForest object at 0x1a256ff8d0>], 'explained': '[ *Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ Random Forest ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.RandomForest object at 0x1a29265090>], 'explained': '[ *Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ Random Forest ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "  \u001b[1mMat52.     \u001b[0;0m  |              value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |  3.126551859046205  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  4.938472530928083  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "!python3 autoprognosis.py\\\n",
    "-i ../../../AutoPrognosisThings/cardio_data/small_cardio_data_7_feature.csv\\\n",
    "--target outcome \\\n",
    "-o ../../../AutoPrognosisThings/outputs \\\n",
    "--it 50 \\\n",
    "--cv 5 \\\n",
    "--nstage 1 \\\n",
    "--modelindexes 0\\\n",
    "--num_components 1\\\n",
    "--kernel_freq 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\r\n",
      "\r\n",
      "classifier      aucroc 0.682\r\n",
      "classifier      aucprc 0.070\r\n",
      "ensemble        aucroc 0.680\r\n",
      "ensemble        aucprc 0.074\r\n",
      "\r\n",
      "Report\r\n",
      "\r\n",
      "best score single pipeline (while fitting)    0.688\r\n",
      "model_names_single_pipeline                   [ Random Forest ]\r\n",
      "best ensemble score (while fittng)            0.688\r\n",
      "ensemble_pipelines                            ['[ Random Forest ]', '[ Random Forest ]', '[ Random Forest ]']\r\n",
      "ensemble_pipelines_weight                     [0.6455330697462757, 0.0, 0.3544669302537244]\r\n",
      "optimisation_metric                           aucroc\r\n",
      "hyperparameter_properties                     [{'name': 'Random Forest', 'hyperparameters': {'model': \"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\\n            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\\n            min_impurity_decrease=0.0, min_impurity_split=None,\\n            min_samples_leaf=50, min_samples_split=2,\\n            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\\n            oob_score=False, random_state=None, verbose=0,\\n            warm_start=False)\"}}]\r\n",
      "acquisition_type                              LCB\r\n",
      "kernel_members                                0 ['Random Forest']\r\n",
      "classes dataset                               [False, True]\r\n",
      "features                                      ['eid', 'gender', 'age-0', 'average-sys-0', 'history-of-diabetes', 'hypertention-medication-0', 'smoker', 'average-BMI-0']\r\n",
      "samples                                       20000\r\n",
      "(0, {'name': 'initial', 'aucroc': 0.6753007998587904})\r\n",
      "sort by aucroc\r\n",
      "# 255\r\n",
      "# 123\r\n",
      "\r\n",
      "Average performance per classifier (ignoring hyperparameters):\r\n",
      "\r\n",
      "  0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.688 0.069\r\n",
      "  1 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=75, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.687 0.080\r\n",
      "  2 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)  11 0.686 0.076\r\n",
      "  3 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.685 0.070\r\n",
      "  4 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)  13 0.685 0.069\r\n",
      "  5 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   3 0.684 0.070\r\n",
      "  6 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.684 0.074\r\n",
      "  7 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.684 0.069\r\n",
      "  8 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   2 0.684 0.073\r\n",
      "  9 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   3 0.684 0.068\r\n",
      " 10 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   2 0.684 0.077\r\n",
      " 11 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.684 0.068\r\n",
      " 12 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.683 0.069\r\n",
      " 13 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.683 0.073\r\n",
      " 14 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.683 0.070\r\n",
      " 15 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.683 0.076\r\n",
      " 16 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)  12 0.683 0.074\r\n",
      " 17 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.682 0.067\r\n",
      " 18 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r",
      "\r\n",
      "            warm_start=False)   1 0.682 0.068\r\n",
      " 19 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.682 0.071\r\n",
      " 20 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)  10 0.681 0.068\r\n",
      " 21 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.681 0.068\r\n",
      " 22 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=75, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.681 0.075\r\n",
      " 23 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.681 0.074\r\n",
      " 24 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   8 0.681 0.069\r\n",
      " 25 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.680 0.070\r\n",
      " 26 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   3 0.679 0.069\r\n",
      " 27 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.679 0.073\r\n",
      " 28 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=75, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.679 0.078\r\n",
      " 29 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.679 0.068\r\n",
      " 30 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.678 0.067\r\n",
      " 31 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.678 0.068\r\n",
      " 32 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.678 0.071\r\n",
      " 33 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.678 0.066\r\n",
      " 34 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.677 0.071\r\n",
      " 35 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.676 0.067\r\n",
      " 36 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.676 0.064\r\n",
      " 37 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.675 0.064\r\n",
      " 38 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=75, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   3 0.674 0.064\r\n",
      " 39 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.673 0.076\r\n",
      " 40 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   2 0.673 0.064\r\n",
      " 41 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.673 0.074\r\n",
      " 42 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.672 0.068\r\n",
      " 43 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   6 0.672 0.065\r\n",
      " 44 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.672 0.064\r\n",
      " 45 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.672 0.062\r\n",
      " 46 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.671 0.064\r\n",
      " 47 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.671 0.064\r\n",
      " 48 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.671 0.064\r\n",
      " 49 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.671 0.064\r\n",
      " 50 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=5, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.671 0.068\r\n",
      " 51 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.671 0.063\r\n",
      " 52 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.670 0.063\r\n",
      " 53 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   8 0.670 0.066\r\n",
      " 54 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.670 0.064\r\n",
      " 55 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.670 0.065\r\n",
      " 56 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.670 0.064\r\n",
      " 57 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)  11 0.669 0.064\r\n",
      " 58 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=75, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.669 0.063\r\n",
      " 59 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   8 0.669 0.068\r\n",
      " 60 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.669 0.065\r\n",
      " 61 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.668 0.066\r\n",
      " 62 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   3 0.668 0.068\r\n",
      " 63 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.668 0.065\r\n",
      " 64 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.667 0.064\r\n",
      " 65 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.667 0.065\r\n",
      " 66 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   3 0.667 0.067\r\n",
      " 67 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.667 0.070\r\n",
      " 68 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.667 0.063\r\n",
      " 69 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.667 0.063\r\n",
      " 70 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=75, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.666 0.063\r\n",
      " 71 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.666 0.063\r\n",
      " 72 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.665 0.062\r\n",
      " 73 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.665 0.063\r\n",
      " 74 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.664 0.062\r\n",
      " 75 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=75, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.664 0.062\r\n",
      " 76 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.664 0.062\r\n",
      " 77 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=100, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.663 0.063\r\n",
      " 78 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.662 0.062\r\n",
      " 79 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)  19 0.662 0.065\r\n",
      " 80 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.662 0.064\r\n",
      " 81 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   3 0.661 0.064\r\n",
      " 82 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.661 0.066\r\n",
      " 83 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.661 0.061\r\n",
      " 84 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   3 0.661 0.067\r\n",
      " 85 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.661 0.061\r\n",
      " 86 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.661 0.060\r\n",
      " 87 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.660 0.062\r\n",
      " 88 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.660 0.063\r\n",
      " 89 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.660 0.067\r\n",
      " 90 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.660 0.060\r\n",
      " 91 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.660 0.065\r\n",
      " 92 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   2 0.659 0.064\r\n",
      " 93 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   8 0.659 0.064\r\n",
      " 94 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=50, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.658 0.061\r\n",
      " 95 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.658 0.064\r\n",
      " 96 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.657 0.065\r\n",
      " 97 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.657 0.061\r\n",
      " 98 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.657 0.062\r\n",
      " 99 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   2 0.656 0.066\r\n",
      "100 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=25, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.656 0.064\r\n",
      "101 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=5, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.655 0.066\r\n",
      "102 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.655 0.061\r\n",
      "103 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.654 0.064\r\n",
      "104 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   2 0.654 0.060\r\n",
      "105 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=5, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.654 0.064\r\n",
      "106 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   2 0.652 0.063\r\n",
      "107 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   2 0.651 0.063\r\n",
      "108 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.651 0.061\r\n",
      "109 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=15, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.651 0.059\r\n",
      "110 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.645 0.058\r\n",
      "111 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.644 0.061\r\n",
      "112 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=20, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.643 0.061\r\n",
      "113 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=30, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.643 0.060\r\n",
      "114 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.642 0.056\r\n",
      "115 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.639 0.061\r\n",
      "116 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=1, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.636 0.056\r\n",
      "117 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=10, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.632 0.056\r\n",
      "118 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=1, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=75, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.630 0.057\r\n",
      "119 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=1, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.625 0.056\r\n",
      "120 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=1, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.624 0.055\r\n",
      "121 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\r\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=1, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=75, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.617 0.053\r\n",
      "122 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\r\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\r\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
      "            min_samples_leaf=1, min_samples_split=2,\r\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\r\n",
      "            oob_score=False, random_state=None, verbose=0,\r\n",
      "            warm_start=False)   1 0.581 0.047\r\n",
      "\r\n",
      "0 {'aucprc': 0.0722404283196534, 'aucroc': 0.6891480755879814, 'name': '[ Random Forest ]', 'cv': 5, 'iter': 23, 'component_idx': 0, 'hyperparameter_properties': [{'name': 'Random Forest', 'hyperparameters': {'model': \"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\\n            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\\n            min_impurity_decrease=0.0, min_impurity_split=None,\\n            min_samples_leaf=30, min_samples_split=2,\\n            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\\n            oob_score=False, random_state=None, verbose=0,\\n            warm_start=False)\"}}], 'model': '<pipelines.basePipeline.basePipeline object at 0x1a2652d890>'}\r\n"
     ]
    }
   ],
   "source": [
    "!python3 autoprognosis_report.py -i ../../../AutoPrognosisThings/outputs --verbose 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model by short simple python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_= pd.read_feather(\"../../../AutoPrognosisThings/cardio_data/Green ICD10 codes/train_df_noNan\")\n",
    "X_.set_index('eid', inplace=True)\n",
    "Y_= pd.read_feather(\"../../../AutoPrognosisThings/cardio_data/Green ICD10 codes/train_df_noNan_outcome\")\n",
    "Y_.set_index('eid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_= pd.read_feather(\"../../../AutoPrognosisThings/cardio_data/ICD10 codes of the paper/train_df_noNan\")\n",
    "X_.set_index('eid', inplace=True)\n",
    "Y_= pd.read_feather(\"../../../AutoPrognosisThings/cardio_data/ICD10 codes of the paper/train_df_noNan_outcome\")\n",
    "Y_.set_index('eid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a small random dataset\n",
    "df_all= X_.join(Y_)\n",
    "df_all=df_all.reindex(np.random.permutation(df_all.index))\n",
    "df_all=df_all[:20000]\n",
    "df_all.to_csv('../../../AutoPrognosisThings/cardio_data/small_cardio_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all= df_all[['gender', 'age-0', 'average-sys-0', 'history-of-diabetes', 'hypertention-medication-0', 'smoker',\n",
    "                'average-BMI-0', 'outcome']]\n",
    "df_all.to_csv('../../../AutoPrognosisThings/cardio_data/small_cardio_data_7_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_= df_all.drop(columns=['outcome'])\n",
    "Y_= df_all[['outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = 'aucprc'\n",
    "acquisition_type = 'MPI' # default and prefered is LCB but this generates excessive warnings, MPI is a good compromise.\n",
    "#I changed kernel_freq=100 and Gibbs_iter=100\n",
    "AP_mdl   = model.AutoPrognosis_Classifier(\n",
    "    metric=metric, CV=5, num_iter=3, kernel_freq=10, ensemble=False,\n",
    "    ensemble_size=3, Gibbs_iter=100, burn_in=50, num_components=3, \n",
    "    acquisition_type=acquisition_type, is_nan=False, use_imputer=False, use_preprocessor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: missForest\n",
      "\n",
      "R[write to console]: Loading required package: randomForest\n",
      "\n",
      "R[write to console]: randomForest 4.6-14\n",
      "\n",
      "R[write to console]: Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "R[write to console]: Loading required package: foreach\n",
      "\n",
      "R[write to console]: Loading required package: itertools\n",
      "\n",
      "R[write to console]: Loading required package: iterators\n",
      "\n",
      "R[write to console]: Loading required package: softImpute\n",
      "\n",
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: Loaded softImpute 1.4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ LinearSVM ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56673d36b6e040f2892e3d3eb113090b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ NeuralNet ]\n",
      "[ MultinomialNaiveBayes ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 43s (43s) (129s), Current pipelines:  [[[ NeuralNet ]]], [[[ MultinomialNaiveBayes ]]], [[[ DecisionTrees ]]], BO objective: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ DecisionTrees ]\n",
      "[ Gradient Boosting ]\n",
      "[ AdaBoost ]\n",
      "[ LDA ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 90s (45s) (135s), Current pipelines:  [[[ Gradient Boosting ]]], [[[ AdaBoost ]]], [[[ LDA ]]], BO objective: -1.0000000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ XGBoost ]\n",
      "[ Bagging ]\n",
      "[ LDA ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 3 146s (49s) (146s), Current pipelines:  [[[ XGBoost ]]], [[[ Bagging ]]], [[[ LDA ]]], BO objective: -1.4142135623730951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ LDA ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'initial', 'aucprc': 0.057172614799005705},\n",
       " {'aucprc': 0.042970511167461346,\n",
       "  'aucroc': 0.6587761425272423,\n",
       "  'name': '[ NeuralNet ]',\n",
       "  'cv': 5,\n",
       "  'iter': 0,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'NeuralNet',\n",
       "    'hyperparameters': {'model': \"MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\\n       hidden_layer_sizes=(50, 50), learning_rate='constant',\\n       learning_rate_init=0.001, max_iter=200, momentum=0.9,\\n       nesterovs_momentum=True, power_t=0.5, random_state=None,\\n       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\\n       verbose=False, warm_start=False)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a25fe9550>'},\n",
       " {'aucprc': 0.026046956029114793,\n",
       "  'aucroc': 0.48341496651951343,\n",
       "  'name': '[ MultinomialNaiveBayes ]',\n",
       "  'cv': 5,\n",
       "  'iter': 0,\n",
       "  'component_idx': 1,\n",
       "  'hyperparameter_properties': [{'name': 'MultinomialNaiveBayes',\n",
       "    'hyperparameters': {'model': 'MultinomialNB(alpha=3.385277405518578, class_prior=None, fit_prior=True)'}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a25fdaf10>'},\n",
       " {'aucprc': 0.0,\n",
       "  'aucroc': 0.5,\n",
       "  'name': '[ DecisionTrees ]',\n",
       "  'cv': 5,\n",
       "  'iter': 0,\n",
       "  'component_idx': 2,\n",
       "  'hyperparameter_properties': [{'name': 'DecisionTrees',\n",
       "    'hyperparameters': {'model': \"DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\\n            max_features=None, max_leaf_nodes=None,\\n            min_impurity_decrease=0.0, min_impurity_split=None,\\n            min_samples_leaf=1, min_samples_split=2,\\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\\n            splitter='best')\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a25ff2610>'},\n",
       " {'aucprc': 0.05638328870905825,\n",
       "  'aucroc': 0.6762716383996976,\n",
       "  'name': '[ Gradient Boosting ]',\n",
       "  'cv': 5,\n",
       "  'iter': 1,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "    'hyperparameters': {'model': \"GradientBoostingClassifier(criterion='friedman_mse', init=None,\\n              learning_rate=0.28105633052522483, loss='deviance',\\n              max_depth=2, max_features=None, max_leaf_nodes=None,\\n              min_impurity_decrease=0.0, min_impurity_split=None,\\n              min_samples_leaf=1, min_samples_split=2,\\n              min_weight_fraction_leaf=0.0, n_estimators=225,\\n              presort='auto', random_state=None, subsample=1.0, verbose=0,\\n              warm_start=False)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fba1f90>'},\n",
       " {'aucprc': 0.027890024965213433,\n",
       "  'aucroc': 0.5283823992040986,\n",
       "  'name': '[ AdaBoost ]',\n",
       "  'cv': 5,\n",
       "  'iter': 1,\n",
       "  'component_idx': 1,\n",
       "  'hyperparameter_properties': [{'name': 'AdaBoost',\n",
       "    'hyperparameters': {'model': \"AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\\n          learning_rate=2.962420135668186, n_estimators=2305,\\n          random_state=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a26093510>'},\n",
       " {'aucprc': 0.0624852889618833,\n",
       "  'aucroc': 0.7249708599993299,\n",
       "  'name': '[ LDA ]',\n",
       "  'cv': 5,\n",
       "  'iter': 1,\n",
       "  'component_idx': 2,\n",
       "  'hyperparameter_properties': [{'name': 'LDA',\n",
       "    'hyperparameters': {'model': \"LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\\n              solver='svd', store_covariance=False, tol=0.0001)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fdca490>'},\n",
       " {'aucprc': 0.048220983902074646,\n",
       "  'aucroc': 0.646021813710327,\n",
       "  'name': '[ XGBoost ]',\n",
       "  'cv': 5,\n",
       "  'iter': 2,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n       colsample_bynode=None, colsample_bytree=None, gamma=None,\\n       gpu_id=None, importance_type='gain', interaction_constraints=None,\\n       learning_rate=0.3691106981794623, max_delta_step=None, max_depth=5,\\n       min_child_weight=None, missing=nan, monotone_constraints=None,\\n       n_estimators=141, n_jobs=None, num_parallel_tree=None,\\n       objective='binary:logistic', random_state=None, reg_alpha=None,\\n       reg_lambda=None, scale_pos_weight=None, subsample=None,\\n       tree_method=None, validate_parameters=False, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fba1810>'},\n",
       " {'aucprc': 0.0572083668943544,\n",
       "  'aucroc': 0.6903383216422755,\n",
       "  'name': '[ Bagging ]',\n",
       "  'cv': 5,\n",
       "  'iter': 2,\n",
       "  'component_idx': 1,\n",
       "  'hyperparameter_properties': [{'name': 'Bagging',\n",
       "    'hyperparameters': {'model': 'BaggingClassifier(base_estimator=None, bootstrap=True,\\n         bootstrap_features=False, max_features=1.0,\\n         max_samples=0.1438421943852849, n_estimators=943, n_jobs=1,\\n         oob_score=False, random_state=None, verbose=0, warm_start=False)'}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fccca50>'},\n",
       " {'aucprc': 0.0624852889618833,\n",
       "  'aucroc': 0.7249708599993299,\n",
       "  'name': '[ LDA ]',\n",
       "  'cv': 5,\n",
       "  'iter': 2,\n",
       "  'component_idx': 2,\n",
       "  'hyperparameter_properties': [{'name': 'LDA',\n",
       "    'hyperparameters': {'model': \"LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\\n              solver='svd', store_covariance=False, tol=0.0001)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x1a1fdfce10>'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.fit(X_, Y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ~~~First element in the output is the predictions of a single model, the second element is the prediction of the ensemble~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.98759929, 0.01240071],\n",
       "        [0.9912874 , 0.0087126 ],\n",
       "        [0.96629033, 0.03370967],\n",
       "        ...,\n",
       "        [0.95964161, 0.04035839],\n",
       "        [0.96429803, 0.03570197],\n",
       "        [0.98756443, 0.01243557]]),\n",
       " array([[0.98759929, 0.01240071],\n",
       "        [0.9912874 , 0.0087126 ],\n",
       "        [0.96629033, 0.03370967],\n",
       "        ...,\n",
       "        [0.95964161, 0.04035839],\n",
       "        [0.96429803, 0.03570197],\n",
       "        [0.98756443, 0.01243557]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.predict(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute performance via multi-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.evaluate_ens(X_, Y_, AP_mdl, n_folds=5, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_mdl.visualize_data(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\r",
       "***Ensemble Report***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank0:   [ XGBoost ],   Ensemble weight: 0.337141036259983**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.classifiers.XGboost object at 0x1a3466ae90>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank1:   [ AdaBoost ],   Ensemble weight: 0.33191778877869144**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.classifiers.Adaboost object at 0x1a34668790>], 'explained': \"[ *AdaBoost, short for Adaptive Boosting, is a machine learning meta-algorithm formulated by Yoav Freund and Robert Schapire, who won the 2003 Gödel Prize for their work. It can be used in conjunction with many other types of learning algorithms to improve performance. The output of the other learning algorithms ('weak learners') is combined into a weighted sum that represents the final output of the boosted classifier. AdaBoost is adaptive in the sense that subsequent weak learners are tweaked in favor of those instances misclassified by previous classifiers.* ]\", 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ AdaBoost ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ *AdaBoost, short for Adaptive Boosting, is a machine learning meta-algorithm formulated by Yoav Freund and Robert Schapire, who won the 2003 Gödel Prize for their work. It can be used in conjunction with many other types of learning algorithms to improve performance. The output of the other learning algorithms ('weak learners') is combined into a weighted sum that represents the final output of the boosted classifier. AdaBoost is adaptive in the sense that subsequent weak learners are tweaked in favor of those instances misclassified by previous classifiers.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank2:   [ XGBoost ],   Ensemble weight: 0.33094117496132563**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.classifiers.XGboost object at 0x1a376f1e90>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "***Kernel Report***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['XGBoost', 'Gradient Boosting', 'Random Forest', 'Neural Network']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mMat52.     \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |  0.9999990030869095  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  0.9031481051397683  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 1**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['Multinomial Naive Bayes', 'Bernoulli Naive Bayes', 'Bagging', 'Adaboost']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mMat52.     \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |  0.9720888366936934  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |   5.127609133763431  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 2**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['Linear SVM', 'KNN', 'Decision Trees', 'Perceptron', 'Logistic Regression', 'Gauss Naive Bayes', 'QDA', 'LDA']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mMat52.     \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |   46.03231114719721  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  21.029530765403038  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_score_single_pipeline': 0.06294085111764766,\n",
       " 'model_names_single_pipeline': '[ XGBoost ]',\n",
       " 'ensemble_score': 0.06402736930011581,\n",
       " 'ensemble_pipelines': ['[ XGBoost ]', '[ AdaBoost ]', '[ XGBoost ]'],\n",
       " 'ensemble_pipelines_weight': [0.337141036259983,\n",
       "  0.33191778877869144,\n",
       "  0.33094117496132563],\n",
       " 'optimisation_metric': 'aucprc',\n",
       " 'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "   'hyperparameters': {'model': \"XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\\n       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\\n       importance_type='gain', interaction_constraints=None,\\n       learning_rate=0.06145542076570746, max_delta_step=0, max_depth=2,\\n       min_child_weight=1, missing=nan, monotone_constraints=None,\\n       n_estimators=253, n_jobs=0, num_parallel_tree=1,\\n       objective='binary:logistic', random_state=0, reg_alpha=0,\\n       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\\n       validate_parameters=False, verbosity=None)\"}}],\n",
       " 'acquisition_type': 'MPI',\n",
       " 'kernel_members': {0: ['XGBoost',\n",
       "   'Gradient Boosting',\n",
       "   'Random Forest',\n",
       "   'Neural Network'],\n",
       "  1: ['Multinomial Naive Bayes',\n",
       "   'Bernoulli Naive Bayes',\n",
       "   'Bagging',\n",
       "   'Adaboost'],\n",
       "  2: ['Linear SVM',\n",
       "   'KNN',\n",
       "   'Decision Trees',\n",
       "   'Perceptron',\n",
       "   'Logistic Regression',\n",
       "   'Gauss Naive Bayes',\n",
       "   'QDA',\n",
       "   'LDA']}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.APReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "state": {
    "b36d11ca14b24a118b3c3a295a788faf": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
