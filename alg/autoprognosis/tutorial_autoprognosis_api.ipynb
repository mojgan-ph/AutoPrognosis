{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoPrognosis API Tutorial\n",
    "\n",
    "A demonstration for AP functionality and operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to use [Autoprognosis](https://arxiv.org/abs/1802.07207). We are using the UCI Spam dataset.\n",
    "\n",
    "See [installation instructions](../../doc/install.md) to install the dependencies.\n",
    "\n",
    "Load dataset and show the first five samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import initpath_ap\n",
    "initpath_ap.init_sys_path()\n",
    "import utilmlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the AutoPrognosis library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--it : total number of iterations for each fold or n-fold cross validation\n",
    "\n",
    "--cv : n for n-fold cross validation\n",
    "\n",
    "--nstage: size of pipeline: 0: auto (selects imputation when missing data is detected),\n",
    "        1: only classifiers, \n",
    "        2: feature processesing + clf, \n",
    "        3: imputers + feature processors and clf\n",
    "        \n",
    "--ensemble : include ensembles when fitting. It gives an assertion error when set to 0! should be looked into.\n",
    "\n",
    "--modelindexes : list of \n",
    "\n",
    "1 Random Forest,\n",
    "2 Gradient Boosting, \n",
    "3 XGBoost, \n",
    "4 Adaboost, \n",
    "5 Bagging, \n",
    "6 Bernoulli Naive Bayes, \n",
    "7 Gauss Naive Bayes, \n",
    "8 Multinomial Naive Bayes, \n",
    "9 Logistic Regression, \n",
    "10 Perceptron, \n",
    "11 Decision Trees, \n",
    "12 QDA, \n",
    "13 LDA, \n",
    "14 KNN, \n",
    "15 Linear SVM, \n",
    "16 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: missForest\n",
      "\n",
      "R[write to console]: Loading required package: randomForest\n",
      "\n",
      "R[write to console]: randomForest 4.6-14\n",
      "\n",
      "R[write to console]: Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "R[write to console]: Loading required package: foreach\n",
      "\n",
      "R[write to console]: Loading required package: itertools\n",
      "\n",
      "R[write to console]: Loading required package: iterators\n",
      "\n",
      "R[write to console]: Loading required package: softImpute\n",
      "\n",
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: Loaded softImpute 1.4\n",
      "\n",
      "\n",
      "[ Random Forest ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ Gradient Boosting ]\n",
      "Iteration number: 1 1s (1s) (4s), Current pipelines:  [[[ Gradient Boosting ]]], BO objective: 0.0\n",
      "[ Random Forest ]\n",
      "Iteration number: 2 5s (2s) (7s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.0\n",
      "[ Random Forest ]\n",
      "Iteration number: 3 9s (3s) (9s), Current pipelines:  [[[ Random Forest ]]], BO objective: -1.072974729982398\n",
      "\n",
      "[ Random Forest ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ Gradient Boosting ]\n",
      "Iteration number: 1 1s (1s) (4s), Current pipelines:  [[[ Gradient Boosting ]]], BO objective: 0.0\n",
      "[ Random Forest ]\n",
      "Iteration number: 2 5s (2s) (7s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.9999999999999983\n",
      "[ Random Forest ]\n",
      "Iteration number: 3 12s (4s) (12s), Current pipelines:  [[[ Random Forest ]]], BO objective: -0.8222424954526381\n",
      "\n",
      "{'model_list': [<models.classifiers.RandomForest object at 0x1a490f8850>], 'explained': '[ *Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ Random Forest ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.RandomForest object at 0x1a2f411650>], 'explained': '[ *Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ Random Forest ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.RandomForest object at 0x1a333c8410>], 'explained': '[ *Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ Random Forest ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "  \u001b[1mMat52.     \u001b[0;0m  |                value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |   0.9999988744721057  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  0.07555957385268447  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "!python3 autoprognosis.py\\\n",
    "-i ../../../AutoPrognosisThings/cardio_data/small_cardio_data_7_feature.csv\\\n",
    "--target outcome \\\n",
    "-o ../../../AutoPrognosisThings/outputs \\\n",
    "--it 3 \\\n",
    "--cv 2 \\\n",
    "--nstage 1 \\\n",
    "--modelindexes 0 1\\\n",
    "--num_components 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\r\n",
      "\r\n",
      "classifier      aucroc 0.678\r\n",
      "classifier      aucprc 0.051\r\n",
      "ensemble        aucroc 0.679\r\n",
      "ensemble        aucprc 0.053\r\n",
      "\r\n",
      "Report\r\n",
      "\r\n",
      "best score single pipeline (while fitting)    0.676\r\n",
      "model_names_single_pipeline                   [ Random Forest ]\r\n",
      "best ensemble score (while fittng)            0.697\r\n",
      "ensemble_pipelines                            ['[ Random Forest ]', '[ Random Forest ]', '[ Random Forest ]']\r\n",
      "ensemble_pipelines_weight                     [0.4670247717753407, 0.2970553824277082, 0.23591984579695116]\r\n",
      "optimisation_metric                           aucroc\r\n",
      "hyperparameter_properties                     [{'name': 'Random Forest', 'hyperparameters': {'model': \"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\\n            min_impurity_decrease=0.0, min_impurity_split=None,\\n            min_samples_leaf=1, min_samples_split=2,\\n            min_weight_fraction_leaf=0.0, n_estimators=699, n_jobs=1,\\n            oob_score=False, random_state=None, verbose=0,\\n            warm_start=False)\"}}]\r\n",
      "acquisition_type                              LCB\r\n",
      "kernel_members                                0 ['Gradient Boosting', 'Random Forest']\r\n",
      "classes dataset                               [False, True]\r\n",
      "features                                      ['eid', 'gender', 'age-0', 'average-sys-0', 'history-of-diabetes', 'hypertention-medication-0', 'smoker', 'average-BMI-0']\r\n",
      "samples                                       20000\r\n",
      "(0, {'name': 'initial', 'aucroc': 0.6759741746959406})\r\n",
      "sort by aucroc\r\n",
      "# 8\r\n",
      "# 2\r\n",
      "\r\n",
      "Average performance per classifier (ignoring hyperparameters):\r\n",
      "\r\n",
      "  0 Random Forest                                        4 0.683 0.052\r\n",
      "  1 Gradient Boosting                                    2 0.624 0.040\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python3 autoprognosis_report.py -i ../../../AutoPrognosisThings/outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model with few iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "df = load_breast_cancer()\n",
    "X_ = pd.DataFrame(df.data)\n",
    "Y_ = pd.DataFrame(df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ mean, Gradient Boosting ]\n",
      "[ most_frequent, MultinomialNaiveBayes ]\n",
      "[ median, LinearSVM ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ mean, XGBoost ]\n",
      "[ mean, BernoullinNaiveBayes ]\n",
      "[ most_frequent, LinearSVM ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 3s (3s) (8s), Current pipelines:  [[[ median, XGBoost ]]], [[[ mean, BernoullinNaiveBayes ]]], [[[ median, LinearSVM ]]], BO objective: -0.9891936728238395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ median, XGBoost ]\n",
      "[ median, BernoullinNaiveBayes ]\n",
      "[ median, QDA ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 5s (3s) (8s), Current pipelines:  [[[ mean, XGBoost ]]], [[[ mean, BernoullinNaiveBayes ]]], [[[ median, QDA ]]], BO objective: -0.9999999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ missForest, Random Forest ]\n",
      "[ mean, Bagging ]\n"
     ]
    }
   ],
   "source": [
    "metric = 'aucprc'\n",
    "acquisition_type = 'MPI' # default and prefered is LCB but this generates excessive warnings, MPI is a good compromise.\n",
    "AP_mdl   = model.AutoPrognosis_Classifier(\n",
    "    metric=metric, CV=5, num_iter=3, kernel_freq=100, ensemble=True,\n",
    "    ensemble_size=3, Gibbs_iter=100, burn_in=50, num_components=3, \n",
    "    acquisition_type=acquisition_type)\n",
    "\n",
    "AP_mdl.fit(X_, Y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ~~~First element in the output is the predictions of a single model, the second element is the prediction of the ensemble~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AP_mdl.predict(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute performance via multi-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_ens(X_, Y_, AP_mdl, n_folds=5, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AP_mdl.visualize_data(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AP_mdl.APReport()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "state": {
    "b36d11ca14b24a118b3c3a295a788faf": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
