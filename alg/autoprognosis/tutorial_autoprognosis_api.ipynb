{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoPrognosis API Tutorial\n",
    "\n",
    "A demonstration for AP functionality and operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to use [Autoprognosis](https://arxiv.org/abs/1802.07207). \n",
    "\n",
    "See [installation instructions](../../doc/install.md) to install the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import initpath_ap\n",
    "initpath_ap.init_sys_path()\n",
    "import utilmlab\n",
    "import json;\n",
    "from scipy import stats\n",
    "#import AutoPrognosis Library:\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introduce with a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>gender</th>\n",
       "      <th>age-0</th>\n",
       "      <th>average-sys-0</th>\n",
       "      <th>history-of-diabetes</th>\n",
       "      <th>hypertention-medication-0</th>\n",
       "      <th>smoker</th>\n",
       "      <th>average-BMI-0</th>\n",
       "      <th>prob</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4049399</td>\n",
       "      <td>0</td>\n",
       "      <td>40.8</td>\n",
       "      <td>128.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.076822</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2461215</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>132.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.570690</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1829764</td>\n",
       "      <td>1</td>\n",
       "      <td>59.6</td>\n",
       "      <td>137.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.274643</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5592240</td>\n",
       "      <td>0</td>\n",
       "      <td>46.1</td>\n",
       "      <td>122.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.040465</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5725915</td>\n",
       "      <td>0</td>\n",
       "      <td>59.1</td>\n",
       "      <td>147.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.066206</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22739</th>\n",
       "      <td>5614020</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5</td>\n",
       "      <td>147.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22740</th>\n",
       "      <td>1979261</td>\n",
       "      <td>0</td>\n",
       "      <td>58.7</td>\n",
       "      <td>130.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22741</th>\n",
       "      <td>5859580</td>\n",
       "      <td>1</td>\n",
       "      <td>40.4</td>\n",
       "      <td>136.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22742</th>\n",
       "      <td>3038532</td>\n",
       "      <td>1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>164.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.365570</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22743</th>\n",
       "      <td>3275778</td>\n",
       "      <td>1</td>\n",
       "      <td>51.2</td>\n",
       "      <td>147.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22744 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           eid  gender  age-0  average-sys-0  history-of-diabetes  \\\n",
       "0      4049399       0   40.8          128.0                False   \n",
       "1      2461215       1   54.0          132.5                False   \n",
       "2      1829764       1   59.6          137.5                False   \n",
       "3      5592240       0   46.1          122.5                False   \n",
       "4      5725915       0   59.1          147.5                False   \n",
       "...        ...     ...    ...            ...                  ...   \n",
       "22739  5614020       1   44.5          147.5                False   \n",
       "22740  1979261       0   58.7          130.5                False   \n",
       "22741  5859580       1   40.4          136.5                False   \n",
       "22742  3038532       1   48.8          164.0                False   \n",
       "22743  3275778       1   51.2          147.0                False   \n",
       "\n",
       "       hypertention-medication-0  smoker  average-BMI-0      prob  outcome  \n",
       "0                          False     0.0           25.9  0.076822    False  \n",
       "1                          False     0.0           24.7  0.570690    False  \n",
       "2                          False     0.0           27.8  0.274643    False  \n",
       "3                          False     0.0           20.0  0.040465    False  \n",
       "4                          False     0.0           36.8  0.066206    False  \n",
       "...                          ...     ...            ...       ...      ...  \n",
       "22739                      False     0.0           26.5  0.005060    False  \n",
       "22740                      False     0.0           23.9  0.001221    False  \n",
       "22741                      False     0.0           26.8  0.001032    False  \n",
       "22742                      False     1.0           30.7  0.365570    False  \n",
       "22743                      False     1.0           29.1  0.016657    False  \n",
       "\n",
       "[22744 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../AutoPrognosisThings/cardio_data/withImage2/with_prob_no_test_vascular.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-i : the input csv file\n",
    "\n",
    "--target : the name of the column that contains the outcome (what you want to predict for the validation/test set)\n",
    "\n",
    "-o : the folder in which the output of AutoPrognosis is written\n",
    "\n",
    "--it : total number of iterations for each fold or n-fold cross validation\n",
    "\n",
    "--cv : If 0, that means a normal validation with train and test (or validation) set. -iValIndex should also be set. Otherwise, n for n-fold cross validation\n",
    "\n",
    "-iValIndex: address of the test index file, test_indexes.csv or val_indexes.csv\", \n",
    "\n",
    "--nstage: size of pipeline: 0: auto (selects imputation when missing data is detected),\n",
    "        1: only classifiers, \n",
    "        2: feature processesing + clf, \n",
    "        3: imputers + feature processors and clf\n",
    "        4: imputers (if needed) + clf\n",
    "        \n",
    "--ensemble : include ensembles when fitting. It gives an assertion error when set to 0! should be looked into.\n",
    "\n",
    "--modelindexes : list of classifiers that we want to try\n",
    "\n",
    "0 Random Forest,\n",
    "1 Gradient Boosting, \n",
    "2 XGBoost, \n",
    "3 Adaboost, \n",
    "4 Bagging, \n",
    "5 Bernoulli Naive Bayes, \n",
    "6 Gauss Naive Bayes, \n",
    "7 Multinomial Naive Bayes, \n",
    "8 Logistic Regression, \n",
    "9 Perceptron, \n",
    "10 Decision Trees, \n",
    "11 QDA, \n",
    "12 LDA, \n",
    "13 KNN, \n",
    "14 Linear SVM, \n",
    "15 Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use AutoPrognosis with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ XGBoost ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=15.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ XGBoost ]\n",
      "Iteration number: 1 5s (5s) (70s), Current pipelines:  [[[ XGBoost ]]], BO objective: 0.0\n",
      "[ XGBoost ]\n",
      "Iteration number: 2 6s (3s) (42s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.0\n",
      "[ XGBoost ]\n",
      "Iteration number: 3 7s (2s) (33s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.3424127458434802\n",
      "[ XGBoost ]\n",
      "Iteration number: 4 7s (2s) (28s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.2871349032045143\n",
      "[ XGBoost ]\n",
      "Iteration number: 5 9s (2s) (26s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.6903393940181122\n",
      "[ XGBoost ]\n",
      "Iteration number: 6 10s (2s) (24s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.7776979952036847\n",
      "[ XGBoost ]\n",
      "Iteration number: 7 11s (2s) (23s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.5305158337751459\n",
      "[ XGBoost ]\n",
      "Iteration number: 8 12s (1s) (22s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.6041377479673005\n",
      "[ XGBoost ]\n",
      "Iteration number: 9 12s (1s) (21s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.387536238099678\n",
      "[ XGBoost ]\n",
      "Iteration number: 10 17s (2s) (25s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.4876037430632416\n",
      "[ XGBoost ]\n",
      "Iteration number: 11 22s (2s) (30s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.591302356493802\n",
      "[ XGBoost ]\n",
      "Iteration number: 12 23s (2s) (29s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.6677213480682127\n",
      "[ XGBoost ]\n",
      "Iteration number: 13 24s (2s) (27s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.7422958608578885\n",
      "[ XGBoost ]\n",
      "Iteration number: 14 25s (2s) (27s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.0092979350248572\n",
      "[ XGBoost ]\n",
      "Iteration number: 15 26s (2s) (26s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.0667491845695631\n",
      "\n",
      "[ XGBoost ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=15.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ XGBoost ]\n",
      "Iteration number: 1 1s (1s) (11s), Current pipelines:  [[[ XGBoost ]]], BO objective: 0.0\n",
      "[ XGBoost ]\n",
      "Iteration number: 2 2s (1s) (12s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.000000000000003\n",
      "[ XGBoost ]\n",
      "Iteration number: 3 3s (1s) (13s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.1250713047424794\n",
      "[ XGBoost ]\n",
      "Iteration number: 4 3s (1s) (12s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.1096870473774356\n",
      "[ XGBoost ]\n",
      "Iteration number: 5 4s (1s) (13s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.305528125328032\n",
      "[ XGBoost ]\n",
      "Iteration number: 6 5s (1s) (13s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.261698988256251\n",
      "[ XGBoost ]\n",
      "Iteration number: 7 6s (1s) (14s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.402013073922509\n",
      "[ XGBoost ]\n",
      "Iteration number: 8 7s (1s) (14s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.2955554836086638\n",
      "[ XGBoost ]\n",
      "Iteration number: 9 8s (1s) (14s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.825454996569912\n",
      "[ XGBoost ]\n",
      "Iteration number: 10 9s (1s) (14s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.5970360404860748\n",
      "[ XGBoost ]\n",
      "Iteration number: 11 10s (1s) (14s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.4627550252210655\n",
      "[ XGBoost ]\n",
      "Iteration number: 12 11s (1s) (14s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.3673849440658734\n",
      "[ XGBoost ]\n",
      "Iteration number: 13 12s (1s) (14s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.3091907496595867\n",
      "[ XGBoost ]\n",
      "Iteration number: 14 13s (1s) (14s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.3844278337675577\n",
      "[ XGBoost ]\n",
      "Iteration number: 15 18s (1s) (18s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.4167079158294695\n",
      "\n",
      "[ XGBoost ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=15.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ XGBoost ]\n",
      "Iteration number: 1 3s (3s) (41s), Current pipelines:  [[[ XGBoost ]]], BO objective: 0.0\n",
      "[ XGBoost ]\n",
      "Iteration number: 2 4s (2s) (31s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.0\n",
      "[ XGBoost ]\n",
      "Iteration number: 3 7s (2s) (35s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.3656927262528515\n",
      "[ XGBoost ]\n",
      "Iteration number: 4 9s (2s) (36s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.2119223442591602\n",
      "[ XGBoost ]\n",
      "Iteration number: 5 12s (2s) (37s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.2020769634912356\n",
      "[ XGBoost ]\n",
      "Iteration number: 6 14s (2s) (34s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.304953473810105\n",
      "[ XGBoost ]\n",
      "Iteration number: 7 16s (2s) (35s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.4576782685541532\n",
      "[ XGBoost ]\n",
      "Iteration number: 8 19s (2s) (36s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.2557422718436484\n",
      "[ XGBoost ]\n",
      "Iteration number: 9 20s (2s) (34s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.253737034995671\n",
      "[ XGBoost ]\n",
      "Iteration number: 10 24s (2s) (37s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.3613569356695363\n",
      "[ XGBoost ]\n",
      "Iteration number: 11 27s (2s) (37s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.4584794989599623\n",
      "[ XGBoost ]\n",
      "Iteration number: 12 28s (2s) (35s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.436377188741028\n",
      "[ XGBoost ]\n",
      "Iteration number: 13 30s (2s) (35s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.5221918505082002\n",
      "[ XGBoost ]\n",
      "Iteration number: 14 32s (2s) (35s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.3823045158162497\n",
      "[ XGBoost ]\n",
      "Iteration number: 15 34s (2s) (34s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.4055999116690783\n",
      "\n",
      "{'model_list': [<models.classifiers.XGboost object at 0x7fe8a7479810>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.XGboost object at 0x7fe8a7479fd0>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.XGboost object at 0x7fe8a7479b50>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "  \u001b[1mMat52.     \u001b[0;0m  |                value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |   0.9377807502398172  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  0.18439380411275477  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "!python3 autoprognosis.py\\\n",
    "-i ../../../AutoPrognosisThings/cardio_data/withImage2/with_prob_no_test_vascular.csv\\\n",
    "--target outcome \\\n",
    "-o ../../../AutoPrognosisThings/outputs \\\n",
    "--it 15 \\\n",
    "--cv 3 \\\n",
    "--nstage 4 \\\n",
    "--modelindexes 2\\\n",
    "--num_components 1\\\n",
    "--kernel_freq 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\r\n",
      "\r\n",
      "classifier      aucroc 0.609\r\n",
      "classifier      aucprc 0.010\r\n",
      "ensemble        aucroc 0.623\r\n",
      "ensemble        aucprc 0.011\r\n",
      "\r\n",
      "Report\r\n",
      "\r\n",
      "best score single pipeline (while fitting)    0.558\r\n",
      "model_names_single_pipeline                   [ XGBoost ]\r\n",
      "best ensemble score (while fittng)            0.604\r\n",
      "ensemble_pipelines                            ['[ XGBoost ]', '[ XGBoost ]', '[ XGBoost ]']\r\n",
      "ensemble_pipelines_weight                     [0.0, 0.07197840433455004, 0.92802159566545]\r\n",
      "optimisation_metric                           aucroc\r\n",
      "hyperparameter_properties                     [{'name': 'XGBoost', 'hyperparameters': {'model': \"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\n              colsample_bynode=1, colsample_bytree=0.6037599731551904,\\n              gamma=5.998657591844557, gpu_id=-1, importance_type='gain',\\n              interaction_constraints='', learning_rate=0.11772659593910406,\\n              max_delta_step=0, max_depth=4,\\n              min_child_weight=0.6282783041435598, missing=nan,\\n              monotone_constraints='()', n_estimators=200, n_jobs=0,\\n              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\\n              scale_pos_weight=1, subsample=0.5, tree_method='exact',\\n              validate_parameters=1, verbosity=None)\"}}]\r\n",
      "acquisition_type                              LCB\r\n",
      "kernel_members                                0 ['XGBoost']\r\n",
      "classes dataset                               [False, True]\r\n",
      "features                                      ['eid', 'gender', 'age-0', 'average-sys-0', 'history-of-diabetes', 'hypertention-medication-0', 'smoker', 'average-BMI-0', 'prob']\r\n",
      "samples                                       22744\r\n",
      "(0, {'name': 'initial', 'aucroc': 0.6473814461800961})\r\n",
      "sort by aucroc\r\n",
      "# 48\r\n",
      "# 46\r\n",
      "/Users/mojgan/opt/anaconda3/envs/mlEnvAuto/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\r\n",
      "  out=out, **kwargs)\r\n",
      "/Users/mojgan/opt/anaconda3/envs/mlEnvAuto/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\r\n",
      "  ret = ret.dtype.type(ret / rcount)\r\n",
      "\r\n",
      "Average performance per classifier (ignoring hyperparameters):\r\n",
      "\r\n",
      "  0 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6414932457450365,\r\n",
      "              gamma=3.9523776451884984, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.1280259889168418,\r\n",
      "              max_delta_step=None, max_depth=5,\r\n",
      "              min_child_weight=0.5665059834726458, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.5414357489880901, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.666 0.011\r\n",
      "  1 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5013851053818015,\r\n",
      "              gamma=3.6276213600772014, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.28908880472083687,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=1.471066335864279, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=50, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.7497467955094455, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.663 0.011\r\n",
      "  2 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6858116785484587,\r\n",
      "              gamma=3.3653523983751223, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.14574418071639308,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=0.9402413568259318, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6954481182307307, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.652 0.014\r\n",
      "  3 initial                                              0 nan nan\r\n",
      "  4 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.9174514881881525,\r\n",
      "              gamma=2.7402558625650295, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.17693907779243434,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.048899735437671, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6318885534844412, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.643 0.028\r\n",
      "  5 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.922515392673636,\r\n",
      "              gamma=8.973588702354498, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.14305642421393322,\r\n",
      "              max_delta_step=None, max_depth=6,\r\n",
      "              min_child_weight=0.6510550478917654, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=300, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.8692053302143284, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.640 0.021\r\n",
      "  6 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.8101561429068779,\r\n",
      "              gamma=4.017137485035558, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.20978758116581334,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.3963976155762738, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.837488739591041, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.636 0.014\r\n",
      "  7 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6081069601812423,\r\n",
      "              gamma=3.547403960228104, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.2887094621991571,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=1.5026443776636673, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=50, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.7746827332412015, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.634 0.007\r\n",
      "  8 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6527629673744647,\r\n",
      "              gamma=3.8218952041398935, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.11154914729176366,\r\n",
      "              max_delta_step=None, max_depth=5,\r\n",
      "              min_child_weight=0.5629228689795773, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.5767983621796122, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.630 0.027\r\n",
      "  9 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.8315787724873618,\r\n",
      "              gamma=4.636194160933915, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.21831195247512705,\r\n",
      "              max_delta_step=None, max_depth=8,\r\n",
      "              min_child_weight=1.610155948149791, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=300, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.9495758948968904, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.628 0.012\r\n",
      " 10 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.7250045823956955,\r\n",
      "              gamma=3.3972927011137704, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.15919607486132795,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=0.9879047910071711, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6900276463242987, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.623 0.015\r\n",
      " 11 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5394103886656036,\r\n",
      "              gamma=7.650659474747146, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.17118235244583982,\r\n",
      "              max_delta_step=None, max_depth=8,\r\n",
      "              min_child_weight=0.5725768109786832, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=500, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.7968804671098109, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.622 0.007\r\n",
      " 12 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6629704994014047,\r\n",
      "              gamma=6.358574466994627, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.16792517668323526,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.7708354940437633, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=400, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.9956500075996159, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.619 0.012\r\n",
      " 13 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.940930678860441,\r\n",
      "              gamma=6.313272398815885, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.12010658912090218,\r\n",
      "              max_delta_step=None, max_depth=2,\r\n",
      "              min_child_weight=0.7431405996824069, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=75, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.8673250449004137, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.619 0.012\r\n",
      " 14 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6283722799580397,\r\n",
      "              gamma=3.4029868786128685, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.10792843985131516,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.0479767157136204, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6641961475299817, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.613 0.006\r\n",
      " 15 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5618367850487894,\r\n",
      "              gamma=3.2472276724595623, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.12278931310900222,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=0.8419306806308591, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6919805069425264, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.611 0.016\r\n",
      " 16 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6721420966224418,\r\n",
      "              gamma=6.850334453190024, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.37312514909267025,\r\n",
      "              max_delta_step=None, max_depth=8,\r\n",
      "              min_child_weight=1.0076787629378983, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.8231079064875724, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.607 0.012\r\n",
      " 17 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6087134171657124,\r\n",
      "              gamma=3.395233983985057, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.06899550032770677,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.1287325275469675, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6539144262458986, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.601 0.008\r\n",
      " 18 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6921596722951062,\r\n",
      "              gamma=3.482841019755306, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.07159481597362537,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.0691097902375333, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.661227363057096, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.599 0.006\r\n",
      " 19 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5711459311972085,\r\n",
      "              gamma=3.4400294586006837, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.06831329215745305,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.0426433118673706, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.7584321525185572, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.598 0.008\r\n",
      " 20 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5466900927620365,\r\n",
      "              gamma=3.4438188362139504, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.06626232904538418,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.0115350403532088, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.5831858081557768, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.595 0.005\r\n",
      " 21 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.64310444485808,\r\n",
      "              gamma=3.3695463140486743, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.24010455293614172,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.0377015589807224, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6640654833533021, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.563 0.006\r\n",
      " 22 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.8089368443114452,\r\n",
      "              gamma=2.8809593265908555, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.33739454594919654,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.071653882465882, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6355785616854782, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.562 0.010\r\n",
      " 23 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6037599731551904,\r\n",
      "              gamma=5.998657591844557, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.11772659593910406,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=0.6282783041435598, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=0.5,\r\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)   1 0.558 0.007\r\n",
      " 24 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.7792545805349602,\r\n",
      "              gamma=2.975339404960978, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.30247056208091566,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.056704576805298, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6420645477157165, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.556 0.006\r\n",
      " 25 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.9053472434904866,\r\n",
      "              gamma=2.06676447674893, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.49791660056134207,\r\n",
      "              max_delta_step=None, max_depth=3,\r\n",
      "              min_child_weight=1.0928013313583407, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6671136496151738, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.540 0.008\r\n",
      " 26 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.8710464658713365,\r\n",
      "              gamma=8.99571210888867, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.31706106343998475,\r\n",
      "              max_delta_step=None, max_depth=6,\r\n",
      "              min_child_weight=0.9610620025242617, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=15, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.7684238752928949, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.539 0.004\r\n",
      " 27 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5736202114319702,\r\n",
      "              gamma=6.183282895179212, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.23420044960984684,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.8464771150190912, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.9169047188864633, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.538 0.009\r\n",
      " 28 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6734957390320766,\r\n",
      "              gamma=5.844366668033743, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.16397839763236977,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=0.6190541186748098, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.5099594217886767, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.536 0.005\r\n",
      " 29 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5482682969388983,\r\n",
      "              gamma=6.222993802293733, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.09575056413107752,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.8666017936730368, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.9047730417188581, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.534 0.006\r\n",
      " 30 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5777974664522367,\r\n",
      "              gamma=6.218481796374659, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.17354132918578913,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.7402667711136317, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.8156225524365429, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.531 0.011\r\n",
      " 31 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5630716044051834,\r\n",
      "              gamma=6.014927544661546, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.2875047364164432,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.7483029885651477, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.8613959147309171, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.527 0.006\r\n",
      " 32 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6479054011927683,\r\n",
      "              gamma=6.1656375807535175, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.14115559735263764,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.9295173355153888, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.7336346078874073, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.520 0.005\r\n",
      " 33 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5570168821306432,\r\n",
      "              gamma=5.946012921310965, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.3624270456964894,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.6670900888220039, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.8568670333359973, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.520 0.006\r\n",
      " 34 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.7368427318613211,\r\n",
      "              gamma=5.704213071354296, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.20599353098064305,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=0.6106758257994254, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6053496720955864, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.518 0.005\r\n",
      " 35 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.9712921041949998,\r\n",
      "              gamma=9.260570337682312, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.1911151467248528,\r\n",
      "              max_delta_step=None, max_depth=9,\r\n",
      "              min_child_weight=0.8528530274930382, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=10, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.9634404645414105, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.500 0.004\r\n",
      " 36 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5197228332355749,\r\n",
      "              gamma=3.800567851428118, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.005,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=0.925992274660537, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6987760385280761, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.500 0.004\r\n",
      " 37 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.86031070287321,\r\n",
      "              gamma=9.958817344045125, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.017256965560542757,\r\n",
      "              max_delta_step=None, max_depth=5,\r\n",
      "              min_child_weight=1.539662849018155, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=20, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.8935879162773541, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.500 0.004\r\n",
      " 38 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.7361988147363502,\r\n",
      "              gamma=3.209836864041201, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.005,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=0.9100417173875697, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.6710138401722116, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.500 0.004\r\n",
      " 39 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.905808147810718,\r\n",
      "              gamma=5.94029858530782, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.005,\r\n",
      "              max_delta_step=None, max_depth=7, min_child_weight=2.0,\r\n",
      "              missing=nan, monotone_constraints=None, n_estimators=200,\r\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None,\r\n",
      "              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.5428790841663003, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.500 0.004\r\n",
      " 40 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5,\r\n",
      "              gamma=5.9626804253870285, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.005,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.8739847897864873, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=1.0,\r\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)   1 0.500 0.004\r\n",
      " 41 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5109744653410143,\r\n",
      "              gamma=6.376593567540726, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.005,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.7470743233718212, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.9088925854344809, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.500 0.004\r\n",
      " 42 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.6376430919764968,\r\n",
      "              gamma=7.573280672140276, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.08679082211596852,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=0.563012269523833, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=20, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.7009204624840326, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.500 0.004\r\n",
      " 43 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.9055287163636746,\r\n",
      "              gamma=2.503064894118714, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.5,\r\n",
      "              max_delta_step=None, max_depth=4,\r\n",
      "              min_child_weight=1.2242765761336922, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=40, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.5970777169981293, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.493 0.011\r\n",
      " 44 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5139701200229707,\r\n",
      "              gamma=0.620231935442459, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.21218120496597373,\r\n",
      "              max_delta_step=None, max_depth=5,\r\n",
      "              min_child_weight=1.6213398992821584, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=500, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.7718327332468614, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.493 0.006\r\n",
      " 45 XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\r\n",
      "              colsample_bynode=None, colsample_bytree=0.5862740078682825,\r\n",
      "              gamma=6.540634151266109, gpu_id=None, importance_type='gain',\r\n",
      "              interaction_constraints=None, learning_rate=0.4873829956062729,\r\n",
      "              max_delta_step=None, max_depth=7,\r\n",
      "              min_child_weight=1.0594235975404191, missing=nan,\r\n",
      "              monotone_constraints=None, n_estimators=200, n_jobs=None,\r\n",
      "              num_parallel_tree=None, random_state=None, reg_alpha=None,\r\n",
      "              reg_lambda=None, scale_pos_weight=None,\r\n",
      "              subsample=0.9141452641499382, tree_method=None,\r\n",
      "              validate_parameters=None, verbosity=None)   1 0.481 0.005\r\n",
      "\r\n",
      "0 {'aucprc': 0.010830795450036063, 'aucroc': 0.6656793310387433, 'name': '[ XGBoost ]', 'cv': 3, 'iter': 3, 'component_idx': 0, 'hyperparameter_properties': [{'name': 'XGBoost', 'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6414932457450365,\\n              gamma=3.9523776451884984, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.1280259889168418,\\n              max_delta_step=None, max_depth=5,\\n              min_child_weight=0.5665059834726458, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.5414357489880901, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}], 'model': '<pipelines.basePipeline.basePipeline object at 0x7fe8a8ce6250>'}\r\n"
     ]
    }
   ],
   "source": [
    "!python3 autoprognosis_report.py -i ../../../AutoPrognosisThings/outputs --verbose 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use AutoPrognosis with train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ XGBoost ]\n",
      "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=15.0, style=ProgressStyle(description_width='initial')), HTML(value='')))\n",
      "[ XGBoost ]\n",
      "Iteration number: 1 1s (1s) (8s), Current pipelines:  [[[ XGBoost ]]], BO objective: 0.0\n",
      "[ XGBoost ]\n",
      "Iteration number: 2 1s (0s) (7s), Current pipelines:  [[[ XGBoost ]]], BO objective: -0.9999999999999971\n",
      "[ XGBoost ]\n",
      "Iteration number: 3 1s (0s) (7s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.1436919220164126\n",
      "[ XGBoost ]\n",
      "Iteration number: 4 2s (0s) (7s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.1629302500688166\n",
      "[ XGBoost ]\n",
      "Iteration number: 5 2s (0s) (7s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.1778641023427532\n",
      "[ XGBoost ]\n",
      "Iteration number: 6 3s (0s) (7s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.2346151646182941\n",
      "[ XGBoost ]\n",
      "Iteration number: 7 3s (0s) (7s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.3617074037630583\n",
      "[ XGBoost ]\n",
      "Iteration number: 8 5s (1s) (10s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.181594687619073\n",
      "[ XGBoost ]\n",
      "Iteration number: 9 6s (1s) (10s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.2673891209340384\n",
      "[ XGBoost ]\n",
      "Iteration number: 10 7s (1s) (10s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.252160881144232\n",
      "[ XGBoost ]\n",
      "Iteration number: 11 7s (1s) (10s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.3498077326762503\n",
      "[ XGBoost ]\n",
      "Iteration number: 12 8s (1s) (10s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.1453772402674038\n",
      "[ XGBoost ]\n",
      "Iteration number: 13 8s (1s) (10s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.1898634790230562\n",
      "[ XGBoost ]\n",
      "Iteration number: 14 9s (1s) (9s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.1931752028574303\n",
      "[ XGBoost ]\n",
      "Iteration number: 15 9s (1s) (9s), Current pipelines:  [[[ XGBoost ]]], BO objective: -1.2140967017578776\n",
      "\n",
      "{'model_list': [<models.classifiers.XGboost object at 0x7fac6f2bf910>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.XGboost object at 0x7fac6f2bf790>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.XGboost object at 0x7fac6f2bf9d0>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "  \u001b[1mMat52.     \u001b[0;0m  |                value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |   1.0440847162779008  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  0.08003660043819212  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "!python3 autoprognosis.py\\\n",
    "-i ../../../AutoPrognosisThings/cardio_data/withImage2/with_prob_no_test_vascular.csv\\\n",
    "-iValIndex ../../../AutoPrognosisThings/cardio_data/val_indexes.csv\\\n",
    "--target outcome \\\n",
    "-o ../../../AutoPrognosisThings/outputs \\\n",
    "--it 15 \\\n",
    "--cv 0 \\\n",
    "--nstage 4 \\\n",
    "--modelindexes 2\\\n",
    "--num_components 1\\\n",
    "--kernel_freq 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model by short simple python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all= pd.read_csv('../../../AutoPrognosisThings/cardio_data/withImage2/with_prob_no_test_vascular.csv')\n",
    "X_= df_all.drop(columns=['outcome'])\n",
    "Y_= df_all[['outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = 'aucprc'\n",
    "acquisition_type = 'MPI' # default and prefered is LCB but this generates excessive warnings, MPI is a good compromise.\n",
    "model.nmax_model= 4 #this is the same as nstage \n",
    "AP_mdl   = model.AutoPrognosis_Classifier(\n",
    "    metric=metric, CV=3, num_iter=3, kernel_freq=100, ensemble=True,\n",
    "    ensemble_size=3, Gibbs_iter=100, burn_in=50, num_components=1, \n",
    "    acquisition_type=acquisition_type, my_model_indexes=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ iterative_extra_trees, XGBoost ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2de87ca5a04b65ac12f8ff76bcb971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=15.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ median, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 2s (2s) (26s), Current pipelines:  [[[ iterative_k_neighbors, XGBoost ]]], BO objective: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ mean, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 3s (2s) (23s), Current pipelines:  [[[ most_frequent, XGBoost ]]], BO objective: -0.9999999999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ iterative_k_neighbors, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 3 5s (2s) (24s), Current pipelines:  [[[ most_frequent, XGBoost ]]], BO objective: -1.1718794767532614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ iterative_k_neighbors, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 4 6s (2s) (24s), Current pipelines:  [[[ iterative_bayesian_ridge, XGBoost ]]], BO objective: -1.3858896698095202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ most_frequent, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 5 8s (2s) (23s), Current pipelines:  [[[ median, XGBoost ]]], BO objective: -1.9183996596867217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ iterative_extra_trees, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 6 17s (3s) (42s), Current pipelines:  [[[ iterative_k_neighbors, XGBoost ]]], BO objective: -1.6988203875266186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ most_frequent, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 7 21s (3s) (44s), Current pipelines:  [[[ most_frequent, XGBoost ]]], BO objective: -1.8550914206237026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ iterative_bayesian_ridge, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 8 29s (4s) (55s), Current pipelines:  [[[ iterative_k_neighbors, XGBoost ]]], BO objective: -1.995293238393431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ mean, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 9 36s (4s) (60s), Current pipelines:  [[[ most_frequent, XGBoost ]]], BO objective: -2.133843484019158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ most_frequent, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 10 38s (4s) (56s), Current pipelines:  [[[ median, XGBoost ]]], BO objective: -2.2597469155801866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ median, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 11 39s (4s) (53s), Current pipelines:  [[[ median, XGBoost ]]], BO objective: -2.3822467716342923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ most_frequent, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 12 40s (3s) (50s), Current pipelines:  [[[ median, XGBoost ]]], BO objective: -2.4208113525769632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ median, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 13 46s (4s) (53s), Current pipelines:  [[[ mean, XGBoost ]]], BO objective: -2.4820401207992244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ iterative_bayesian_ridge, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 14 55s (4s) (59s), Current pipelines:  [[[ iterative_k_neighbors, XGBoost ]]], BO objective: -2.573264724272256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ iterative_extra_trees, XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 15 65s (4s) (65s), Current pipelines:  [[[ mean, XGBoost ]]], BO objective: -2.6751308594506105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ iterative_decision_tree, XGBoost ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       " |||| Now building the ensemble..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble: **['[ iterative_k_neighbors, XGBoost ]', '[ median, XGBoost ]', '[ most_frequent, XGBoost ]']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble weights: **[0.25229537 0.36119685 0.38650777]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The ensemble did not help.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'initial', 'aucprc': 0.01039209853612671},\n",
       " {'aucprc': 0.006940416282112655,\n",
       "  'aucroc': 0.5962493036614914,\n",
       "  'name': '[ median, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 0,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'median'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.7880654774490066,\\n              gamma=4.713279704681442, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.4480875017386628,\\n              max_delta_step=None, max_depth=7,\\n              min_child_weight=1.7594675241891482, missing=nan,\\n              monotone_constraints=None, n_estimators=50, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.9711233497616982, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf64380cd0>'},\n",
       " {'aucprc': 0.008877399339966263,\n",
       "  'aucroc': 0.6267069632450005,\n",
       "  'name': '[ mean, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 1,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'mean'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6837640649346629,\\n              gamma=3.370051475714002, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.17228175456400616,\\n              max_delta_step=None, max_depth=4,\\n              min_child_weight=1.0059453001782146, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6698102993830115, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf6320ef90>'},\n",
       " {'aucprc': 0.00856385000397345,\n",
       "  'aucroc': 0.611929527741239,\n",
       "  'name': '[ iterative_k_neighbors, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 2,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'iterative_k_neighbors'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.9782746082719205,\\n              gamma=3.361941718028092, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.11703808645387924,\\n              max_delta_step=None, max_depth=4,\\n              min_child_weight=1.222099777602661, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7654547824266986, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf6321c210>'},\n",
       " {'aucprc': 0.017991684281543262,\n",
       "  'aucroc': 0.6465911924443829,\n",
       "  'name': '[ iterative_k_neighbors, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 3,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'iterative_k_neighbors'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.8782064164475011,\\n              gamma=0.6617922619368899, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.45909080507948896,\\n              max_delta_step=None, max_depth=3,\\n              min_child_weight=1.6774811840156678, missing=nan,\\n              monotone_constraints=None, n_estimators=15, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.8960612338247049, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf6400e210>'},\n",
       " {'aucprc': 0.02165049492204985,\n",
       "  'aucroc': 0.6508875368364822,\n",
       "  'name': '[ most_frequent, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 4,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'most_frequent'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.8791341468540339,\\n              gamma=0.6713188281096989, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.46041937776928454,\\n              max_delta_step=None, max_depth=3,\\n              min_child_weight=1.6839447424385967, missing=nan,\\n              monotone_constraints=None, n_estimators=15, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.8989436199582187, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf64096610>'},\n",
       " {'aucprc': 0.00662929710039833,\n",
       "  'aucroc': 0.6275848283890381,\n",
       "  'name': '[ iterative_extra_trees, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 5,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'iterative_extra_trees'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.543755398974382,\\n              gamma=8.401270368919688, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.21187683524945344,\\n              max_delta_step=None, max_depth=5,\\n              min_child_weight=1.6249329778959325, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7953144037500528, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf64d64850>'},\n",
       " {'aucprc': 0.006122703631105703,\n",
       "  'aucroc': 0.5926009393157042,\n",
       "  'name': '[ most_frequent, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 6,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'most_frequent'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.8284046215579777,\\n              gamma=0.9385880997398421, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.27976964860833453,\\n              max_delta_step=None, max_depth=7,\\n              min_child_weight=1.2586731259998016, missing=nan,\\n              monotone_constraints=None, n_estimators=150, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.5166271785614944, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf574094d0>'},\n",
       " {'aucprc': 0.00641188486231893,\n",
       "  'aucroc': 0.6156452203745029,\n",
       "  'name': '[ iterative_bayesian_ridge, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 7,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'iterative_bayesian_ridge'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.8740255590112076,\\n              gamma=4.352909719190654, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.273066634658392,\\n              max_delta_step=None, max_depth=5,\\n              min_child_weight=0.5360481339370785, missing=nan,\\n              monotone_constraints=None, n_estimators=500, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6110461249747088, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf64d64610>'},\n",
       " {'aucprc': 0.009801236113546526,\n",
       "  'aucroc': 0.602142790602547,\n",
       "  'name': '[ mean, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 8,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'mean'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.9267043422215887,\\n              gamma=9.726400311058551, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.4325866517421547,\\n              max_delta_step=None, max_depth=5,\\n              min_child_weight=1.9447276757881622, missing=nan,\\n              monotone_constraints=None, n_estimators=400, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.518112335699434, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf57463410>'},\n",
       " {'aucprc': 0.009560091642922262,\n",
       "  'aucroc': 0.6189335082526327,\n",
       "  'name': '[ most_frequent, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 9,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'most_frequent'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.7930475531550912,\\n              gamma=0.8455505789818585, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.3962296831602028,\\n              max_delta_step=None, max_depth=3,\\n              min_child_weight=1.6868595802741493, missing=nan,\\n              monotone_constraints=None, n_estimators=15, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.874940535063228, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf631cf390>'},\n",
       " {'aucprc': 0.003605342612803789,\n",
       "  'aucroc': 0.5,\n",
       "  'name': '[ median, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 10,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'median'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.9590934595715379,\\n              gamma=8.433444021056808, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.2591251727551129,\\n              max_delta_step=None, max_depth=6,\\n              min_child_weight=1.801803448054928, missing=nan,\\n              monotone_constraints=None, n_estimators=10, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7578705568222512, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf6667f1d0>'},\n",
       " {'aucprc': 0.0038001391180565096,\n",
       "  'aucroc': 0.5091346712838637,\n",
       "  'name': '[ most_frequent, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 11,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'most_frequent'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.8519815748339822,\\n              gamma=6.8637201974688, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.20176376885285832,\\n              max_delta_step=None, max_depth=4,\\n              min_child_weight=0.5169527800336031, missing=nan,\\n              monotone_constraints=None, n_estimators=20, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6731929711311743, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf64380f10>'},\n",
       " {'aucprc': 0.005018923067300524,\n",
       "  'aucroc': 0.5605764305349514,\n",
       "  'name': '[ median, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 12,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'median'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.8072334959595849,\\n              gamma=0.7690966371364272, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.18155230980128473,\\n              max_delta_step=None, max_depth=3,\\n              min_child_weight=1.951468736740471, missing=nan,\\n              monotone_constraints=None, n_estimators=500, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6173833407904715, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf6667fed0>'},\n",
       " {'aucprc': 0.007747981405723863,\n",
       "  'aucroc': 0.5825648511201419,\n",
       "  'name': '[ iterative_bayesian_ridge, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 13,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'iterative_bayesian_ridge'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.9454494929542929,\\n              gamma=1.0234389359762963, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.4629465151866175,\\n              max_delta_step=None, max_depth=6,\\n              min_child_weight=1.6055138570065417, missing=nan,\\n              monotone_constraints=None, n_estimators=500, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6625575761432949, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf667bc350>'},\n",
       " {'aucprc': 0.005486297697927447,\n",
       "  'aucroc': 0.6149269644217134,\n",
       "  'name': '[ iterative_extra_trees, XGBoost ]',\n",
       "  'cv': 3,\n",
       "  'iter': 14,\n",
       "  'component_idx': 0,\n",
       "  'hyperparameter_properties': [{'name': 'iterative_extra_trees'},\n",
       "   {'name': 'XGBoost',\n",
       "    'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.8286838677684782,\\n              gamma=5.822416274374237, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.4427523286350698,\\n              max_delta_step=None, max_depth=5,\\n              min_child_weight=1.006705507695411, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7141244526423942, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf642d2a10>'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.fit(X_, Y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.       , 0.       ],\n",
       "        [0.9966131, 0.0033869],\n",
       "        [1.       , 0.       ],\n",
       "        ...,\n",
       "        [1.       , 0.       ],\n",
       "        [1.       , 0.       ],\n",
       "        [1.       , 0.       ]]),\n",
       " array([[1.       , 0.       ],\n",
       "        [0.9966131, 0.0033869],\n",
       "        [1.       , 0.       ],\n",
       "        ...,\n",
       "        [1.       , 0.       ],\n",
       "        [1.       , 0.       ],\n",
       "        [1.       , 0.       ]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.predict(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute performance via multi-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351b35e454ce4e65a22c8ff0ff8bd0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 16s (16s) (47s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 21s (10s) (31s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -1.0000000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 3 32s (11s) (32s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -1.2374465694648809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ Random Forest ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       " |||| Now building the ensemble..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble: **['[ Random Forest ]', '[ XGBoost ]', '[ XGBoost ]']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble weights: **[0.27163174 0.40600177 0.32236649]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The ensemble helps!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score: **0.006852069046771825"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score with ensembles: **0.015280453880859834"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d224567b8c46ce9971a29e60cf1242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 19s (19s) (58s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 36s (18s) (54s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -1.0000000000000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 3 55s (18s) (55s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -1.4099179535164272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ Random Forest ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       " |||| Now building the ensemble..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble: **['[ Random Forest ]', '[ XGBoost ]', '[ Random Forest ]']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble weights: **[0.39796249 0.26020409 0.34183342]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The ensemble did not help.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score: **0.005940358377233659"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score with ensembles: **0.006913172688631486"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2da13957024f46b6383f8aeeb1c0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 12s (12s) (36s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 20s (10s) (30s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -1.0000000000000027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 3 27s (9s) (27s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -0.9807623403368827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ Random Forest ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       " |||| Now building the ensemble..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble: **['[ Random Forest ]', '[ Gradient Boosting ]', '[ Gradient Boosting ]']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble weights: **[0.27587618 0.36073463 0.3633892 ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The ensemble helps!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score: **0.020551837507961877"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score with ensembles: **0.01641602190575411"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0403e6a43a984eb4beb0a33e042b33cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 49s (49s) (146s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 92s (46s) (138s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -1.0000000000000018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 3 116s (39s) (116s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -1.3847233066688105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ XGBoost ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       " |||| Now building the ensemble..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble: **['[ XGBoost ]', '[ XGBoost ]', '[ Random Forest ]']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble weights: **[0.61124475 0.25877672 0.12997853]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The ensemble helps!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score: **0.009704311701573074"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score with ensembles: **0.00987399054978173"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b029120f5a54a919ae570f7d8894959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BO progress', max=3.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 1 44s (44s) (132s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 2 97s (48s) (145s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -1.0000000000000022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Random Forest ]\n",
      "[ Gradient Boosting ]\n",
      "[ XGBoost ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration number: 3 149s (50s) (149s), Current pipelines:  [[[ Random Forest ]]], [[[ Gradient Boosting ]]], [[[ XGBoost ]]], BO objective: -1.4016866640032788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ Random Forest ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       " |||| Now building the ensemble..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble: **['[ Random Forest ]', '[ Random Forest ]', '[ Random Forest ]']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble weights: **[0.2270951  0.38182989 0.39107501]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The ensemble helps!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score: **0.010723521115980402"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Cross-validation score with ensembles: **0.009281237359205016"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Final Cross-validation score: **(0.010754419549904169, 0.0045629979398715305)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Final Cross-validation score with ensembles: **(0.011552975276846435, 0.0032098761530330896)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.010754419549904169, 0.0045629979398715305),\n",
       " (0.011552975276846435, 0.0032098761530330896),\n",
       " {'clf': {'roc_lst': [0.5675601147143171,\n",
       "    0.5364135230531657,\n",
       "    0.6484281709153211,\n",
       "    0.6631016042780747,\n",
       "    0.7185983009708738],\n",
       "   'prc_lst': [0.006852069046771825,\n",
       "    0.005940358377233659,\n",
       "    0.020551837507961877,\n",
       "    0.009704311701573074,\n",
       "    0.010723521115980402],\n",
       "   'roc_cur': 0.7185983009708738,\n",
       "   'prc_cur': 0.010723521115980402},\n",
       "  'clf_ens': {'roc_lst': [0.6018158504301787,\n",
       "    0.6324936576218839,\n",
       "    0.6306006957063496,\n",
       "    0.7049543118218161,\n",
       "    0.686658759929391],\n",
       "   'prc_lst': [0.015280453880859834,\n",
       "    0.006913172688631486,\n",
       "    0.01641602190575411,\n",
       "    0.00987399054978173,\n",
       "    0.009281237359205016],\n",
       "   'roc_cur': 0.686658759929391,\n",
       "   'prc_cur': 0.009281237359205016}},\n",
       " <model.AutoPrognosis_Classifier at 0x7fbf3af6e890>,\n",
       " [[{'name': 'initial', 'aucprc': 0.00980245552290891},\n",
       "   {'aucprc': 0.006768763091619896,\n",
       "    'aucroc': 0.544009096425115,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(criterion='entropy', max_features=None, n_estimators=30)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf62fe0550>'},\n",
       "   {'aucprc': 0.004268895885397956,\n",
       "    'aucroc': 0.48472437430736287,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.46299529150500046, max_depth=8)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf631f9a10>'},\n",
       "   {'aucprc': 0.006518637982807205,\n",
       "    'aucroc': 0.6244515316995872,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6203289498504356,\\n              gamma=1.510698381218547, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.33179438273105877,\\n              max_delta_step=None, max_depth=7,\\n              min_child_weight=1.9342532549366782, missing=nan,\\n              monotone_constraints=None, n_estimators=100, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.5711999187923256, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf66958f50>'},\n",
       "   {'aucprc': 0.00839068695964611,\n",
       "    'aucroc': 0.5858443779178514,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(max_features='sqrt', min_samples_leaf=10,\\n                       n_estimators=30)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f0f75d0>'},\n",
       "   {'aucprc': 0.005312934597119137,\n",
       "    'aucroc': 0.5252182590425184,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.23508756474705853, max_depth=4,\\n                           n_estimators=40)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf665e63d0>'},\n",
       "   {'aucprc': 0.010974786116343496,\n",
       "    'aucroc': 0.6656148611717039,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6838587799262599,\\n              gamma=3.2043561525420565, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.16966199023870393,\\n              max_delta_step=None, max_depth=4,\\n              min_child_weight=1.0494377828401935, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6438973851924307, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf665e6fd0>'},\n",
       "   {'aucprc': 0.011325652393319821,\n",
       "    'aucroc': 0.6826894628896945,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(max_features='sqrt', min_samples_leaf=10,\\n                       n_estimators=30)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf64033f90>'},\n",
       "   {'aucprc': 0.005312173690739434,\n",
       "    'aucroc': 0.5113191320786886,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.2980210973685217, max_depth=4,\\n                           n_estimators=150)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf62fe0450>'},\n",
       "   {'aucprc': 0.01083292281548065,\n",
       "    'aucroc': 0.6711534507745,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6863964332380793,\\n              gamma=3.1853183899039763, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.16961209803306074,\\n              max_delta_step=None, max_depth=4,\\n              min_child_weight=1.0567350801837005, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6405365102305396, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf63023950>'}],\n",
       "  [{'name': 'initial', 'aucprc': 0.014972041888788395},\n",
       "   {'aucprc': 0.034768959780924195,\n",
       "    'aucroc': 0.6339516294836499,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': 'RandomForestClassifier(max_features=None, min_samples_leaf=20, n_estimators=40)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf66954950>'},\n",
       "   {'aucprc': 0.009856612229202024,\n",
       "    'aucroc': 0.5964790215576249,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.46208744228751153, max_depth=2,\\n                           n_estimators=500)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf66954e50>'},\n",
       "   {'aucprc': 0.007516674189350307,\n",
       "    'aucroc': 0.6409319071903882,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.8462957300568513,\\n              gamma=3.8748794902280292, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.10251917564963692,\\n              max_delta_step=None, max_depth=9,\\n              min_child_weight=0.9763561563325922, missing=nan,\\n              monotone_constraints=None, n_estimators=100, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7333628383019606, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f0826d0>'},\n",
       "   {'aucprc': 0.013101914614834021,\n",
       "    'aucroc': 0.6725349640706252,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(max_features='sqrt', min_samples_leaf=20,\\n                       n_estimators=40)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f08c590>'},\n",
       "   {'aucprc': 0.008945515337510626,\n",
       "    'aucroc': 0.5734772012696884,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.43112617571026507, max_depth=2,\\n                           n_estimators=500)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f0ac850>'},\n",
       "   {'aucprc': 0.022967310817390577,\n",
       "    'aucroc': 0.6535824068920214,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6443952215326546,\\n              gamma=3.4583316341492605, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.16597865653241986,\\n              max_delta_step=None, max_depth=4,\\n              min_child_weight=1.0306037820523133, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6937906428747134, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f0ac190>'},\n",
       "   {'aucprc': 0.01062789428910551,\n",
       "    'aucroc': 0.6592701798725297,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(criterion='entropy', max_features=None,\\n                       min_samples_leaf=20, n_estimators=40)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f079910>'},\n",
       "   {'aucprc': 0.00825557090313426,\n",
       "    'aucroc': 0.584158229657154,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.49617995686573324, max_depth=2,\\n                           n_estimators=500)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f079a90>'},\n",
       "   {'aucprc': 0.003627370156636439,\n",
       "    'aucroc': 0.5,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.8871670442569456,\\n              gamma=9.5900843046912, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.03519216820780796,\\n              max_delta_step=None, max_depth=8,\\n              min_child_weight=0.9171540625045651, missing=nan,\\n              monotone_constraints=None, n_estimators=100, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7804564879447355, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf640b72d0>'}],\n",
       "  [{'name': 'initial', 'aucprc': 0.006828857388430286},\n",
       "   {'aucprc': 0.006220806139734448,\n",
       "    'aucroc': 0.6145157379296938,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(max_features='sqrt', min_samples_leaf=20,\\n                       n_estimators=200)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf57409e10>'},\n",
       "   {'aucprc': 0.006900674157958982,\n",
       "    'aucroc': 0.6625932189293974,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.16399120988364324, max_depth=1,\\n                           n_estimators=20)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf66954e10>'},\n",
       "   {'aucprc': 0.006423606775913353,\n",
       "    'aucroc': 0.6059224697916051,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6757763548885459,\\n              gamma=4.670105314587316, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.06409065489633253,\\n              max_delta_step=None, max_depth=8,\\n              min_child_weight=1.841979099874841, missing=nan,\\n              monotone_constraints=None, n_estimators=400, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6932148821960535, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf66954dd0>'},\n",
       "   {'aucprc': 0.006723203872323453,\n",
       "    'aucroc': 0.557133725315665,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(max_features='sqrt', min_samples_leaf=10,\\n                       n_estimators=30)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf573de710>'},\n",
       "   {'aucprc': 0.007098909566135805,\n",
       "    'aucroc': 0.6495854986484627,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.10512539715930272, max_depth=1,\\n                           n_estimators=20)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f284850>'},\n",
       "   {'aucprc': 0.006343973010389255,\n",
       "    'aucroc': 0.6108753792345946,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6742850936812971,\\n              gamma=4.653635741971064, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.07532208937229816,\\n              max_delta_step=None, max_depth=8,\\n              min_child_weight=1.8217140656571438, missing=nan,\\n              monotone_constraints=None, n_estimators=400, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7013519554643053, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf6400e3d0>'},\n",
       "   {'aucprc': 0.007536546053123119,\n",
       "    'aucroc': 0.5976806391081108,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(max_features='sqrt', min_samples_leaf=10,\\n                       n_estimators=30)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f0af650>'},\n",
       "   {'aucprc': 0.006819192556526563,\n",
       "    'aucroc': 0.6457440640769735,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.09572114209765528, max_depth=1,\\n                           n_estimators=20)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf662b6450>'},\n",
       "   {'aucprc': 0.006352819496295595,\n",
       "    'aucroc': 0.6166109520360485,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.5767215715596948,\\n              gamma=5.172397343167569, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.02656369057133637,\\n              max_delta_step=None, max_depth=9,\\n              min_child_weight=1.849894337205018, missing=nan,\\n              monotone_constraints=None, n_estimators=400, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7977966038062381, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f22bf50>'}],\n",
       "  [{'name': 'initial', 'aucprc': 0.005986465938128012},\n",
       "   {'aucprc': 0.006086942964564255,\n",
       "    'aucroc': 0.5556829826709117,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': 'RandomForestClassifier(max_features=None, min_samples_leaf=10, n_estimators=300)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf631f9350>'},\n",
       "   {'aucprc': 0.004893891100322341,\n",
       "    'aucroc': 0.5411408779800078,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.42714033772595605, max_depth=7,\\n                           n_estimators=300)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf62fe6fd0>'},\n",
       "   {'aucprc': 0.005180911048414393,\n",
       "    'aucroc': 0.5525553469695622,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.5310730108937332,\\n              gamma=9.701749383191075, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.46133429828346495,\\n              max_delta_step=None, max_depth=9,\\n              min_child_weight=0.8401638559832711, missing=nan,\\n              monotone_constraints=None, n_estimators=200, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7615607355169492, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf66958350>'},\n",
       "   {'aucprc': 0.005652357002831836,\n",
       "    'aucroc': 0.5451382936105129,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': 'RandomForestClassifier(max_features=None, min_samples_leaf=10, n_estimators=300)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf642ca890>'},\n",
       "   {'aucprc': 0.004241666614943165,\n",
       "    'aucroc': 0.5250123470386113,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.5, max_depth=7, n_estimators=300)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf62fec650>'},\n",
       "   {'aucprc': 0.0058450726479694765,\n",
       "    'aucroc': 0.6357088078474725,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6563232731527546,\\n              gamma=3.407939373206009, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.11101085030438437,\\n              max_delta_step=None, max_depth=4,\\n              min_child_weight=1.037372424983793, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6280855713668573, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf642ca390>'},\n",
       "   {'aucprc': 0.005221063256060283,\n",
       "    'aucroc': 0.5323972202917496,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(max_features='sqrt', min_samples_leaf=10,\\n                       n_estimators=30)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3ae1a150>'},\n",
       "   {'aucprc': 0.004465733155760487,\n",
       "    'aucroc': 0.5061362804225339,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.426518187578095, max_depth=7,\\n                           n_estimators=300)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3ae1a750>'},\n",
       "   {'aucprc': 0.007495708678184267,\n",
       "    'aucroc': 0.6123519178386386,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.7180855122063291,\\n              gamma=7.8796007763396645, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.30926517869164005,\\n              max_delta_step=None, max_depth=5,\\n              min_child_weight=1.452082735429298, missing=nan,\\n              monotone_constraints=None, n_estimators=75, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.802727734704874, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf640c6710>'}],\n",
       "  [{'name': 'initial', 'aucprc': 0.00755573022672304},\n",
       "   {'aucprc': 0.012509687198492053,\n",
       "    'aucroc': 0.6005951271733598,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(criterion='entropy', max_features=0.8,\\n                       min_samples_leaf=10)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3ae1ad10>'},\n",
       "   {'aucprc': 0.005641148220473735,\n",
       "    'aucroc': 0.5641743129194015,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.25745421991916256, max_depth=8,\\n                           n_estimators=400)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf57463f10>'},\n",
       "   {'aucprc': 0.007167477704284268,\n",
       "    'aucroc': 0.6242060473066715,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 0,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6588546585652598,\\n              gamma=7.238110756668293, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.21968531071262049,\\n              max_delta_step=None, max_depth=6,\\n              min_child_weight=0.7111317241919828, missing=nan,\\n              monotone_constraints=None, n_estimators=50, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.9801506340970093, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf6302a790>'},\n",
       "   {'aucprc': 0.011374709634779427,\n",
       "    'aucroc': 0.6029818058836831,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(criterion='entropy', max_features=0.8,\\n                       min_samples_leaf=10)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf4bf3f410>'},\n",
       "   {'aucprc': 0.008016428592404276,\n",
       "    'aucroc': 0.5659718316172412,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.23369034283548135, max_depth=8,\\n                           n_estimators=400)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf6320e390>'},\n",
       "   {'aucprc': 0.007100820957673076,\n",
       "    'aucroc': 0.6524865683686025,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 1,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.6357565418362584,\\n              gamma=3.312994830100193, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.16185577606724622,\\n              max_delta_step=None, max_depth=4,\\n              min_child_weight=0.9355870687084639, missing=nan,\\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.7041489181987676, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf6321c690>'},\n",
       "   {'aucprc': 0.009945839218902722,\n",
       "    'aucroc': 0.6092673173212125,\n",
       "    'name': '[ Random Forest ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 0,\n",
       "    'hyperparameter_properties': [{'name': 'Random Forest',\n",
       "      'hyperparameters': {'model': \"RandomForestClassifier(criterion='entropy', max_features=0.8,\\n                       min_samples_leaf=10)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf62fe05d0>'},\n",
       "   {'aucprc': 0.007024420219947013,\n",
       "    'aucroc': 0.5156693938860623,\n",
       "    'name': '[ Gradient Boosting ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 1,\n",
       "    'hyperparameter_properties': [{'name': 'Gradient Boosting',\n",
       "      'hyperparameters': {'model': 'GradientBoostingClassifier(learning_rate=0.19751408883862467, max_depth=8,\\n                           n_estimators=400)'}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f189590>'},\n",
       "   {'aucprc': 0.005352342626865059,\n",
       "    'aucroc': 0.49531199580014884,\n",
       "    'name': '[ XGBoost ]',\n",
       "    'cv': 3,\n",
       "    'iter': 2,\n",
       "    'component_idx': 2,\n",
       "    'hyperparameter_properties': [{'name': 'XGBoost',\n",
       "      'hyperparameters': {'model': \"XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=0.7032865335646685,\\n              gamma=0.8618073879191568, gpu_id=None, importance_type='gain',\\n              interaction_constraints=None, learning_rate=0.48265668100773035,\\n              max_delta_step=None, max_depth=3,\\n              min_child_weight=1.4271481771361971, missing=nan,\\n              monotone_constraints=None, n_estimators=150, n_jobs=None,\\n              num_parallel_tree=None, random_state=None, reg_alpha=None,\\n              reg_lambda=None, scale_pos_weight=None,\\n              subsample=0.6173715807352083, tree_method=None,\\n              validate_parameters=None, verbosity=None)\"}}],\n",
       "    'model': '<pipelines.basePipeline.basePipeline object at 0x7fbf3f181510>'}]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_ens(X_, Y_, AP_mdl, n_folds=3, visualize=True, X_val_indexes=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbf3f189a90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.visualize_data(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\r",
       "***Ensemble Report***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank0:   [ iterative_k_neighbors, XGBoost ],   Ensemble weight: 0.2522953737697456**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.imputers.iterative_k_neighbors object at 0x7fbf64232d50>, <models.classifiers.XGboost object at 0x7fbf6320c610>], 'explained': '[ , *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 2, 'pipeline_stages': ['imputer', 'classifier'], 'name': '[ iterative_k_neighbors, XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ , *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank1:   [ median, XGBoost ],   Ensemble weight: 0.3611968514171138**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.imputers.median object at 0x7fbf64232a10>, <models.classifiers.XGboost object at 0x7fbf6320c410>], 'explained': '[ , *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 2, 'pipeline_stages': ['imputer', 'classifier'], 'name': '[ median, XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ , *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank2:   [ most_frequent, XGBoost ],   Ensemble weight: 0.38650777481314064**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.imputers.most_frequent object at 0x7fbf64232bd0>, <models.classifiers.XGboost object at 0x7fbf6320cfd0>], 'explained': '[ , *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 2, 'pipeline_stages': ['imputer', 'classifier'], 'name': '[ most_frequent, XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ , *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "***Kernel Report***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['XGBoost']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mMat52.     \u001b[0;0m  |                 value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |     0.765128065717315  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  0.021327189746694973  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_score_single_pipeline': 0.02165049492204985,\n",
       " 'model_names_single_pipeline': '[ iterative_decision_tree, XGBoost ]',\n",
       " 'ensemble_score': 0.01664557078126209,\n",
       " 'ensemble_pipelines': ['[ iterative_k_neighbors, XGBoost ]',\n",
       "  '[ median, XGBoost ]',\n",
       "  '[ most_frequent, XGBoost ]'],\n",
       " 'ensemble_pipelines_weight': [0.2522953737697456,\n",
       "  0.3611968514171138,\n",
       "  0.38650777481314064],\n",
       " 'optimisation_metric': 'aucprc',\n",
       " 'hyperparameter_properties': [{'name': 'iterative_decision_tree'},\n",
       "  {'name': 'XGBoost',\n",
       "   'hyperparameters': {'model': \"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\n              colsample_bynode=1, colsample_bytree=0.8791341468540339,\\n              gamma=0.6713188281096989, gpu_id=-1, importance_type='gain',\\n              interaction_constraints='', learning_rate=0.46041937776928454,\\n              max_delta_step=0, max_depth=3,\\n              min_child_weight=1.6839447424385967, missing=nan,\\n              monotone_constraints='()', n_estimators=15, n_jobs=0,\\n              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\\n              scale_pos_weight=1, subsample=0.8989436199582187,\\n              tree_method='exact', validate_parameters=1, verbosity=None)\"}}],\n",
       " 'acquisition_type': 'MPI',\n",
       " 'kernel_members': {0: ['XGBoost']}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.APReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "state": {
    "b36d11ca14b24a118b3c3a295a788faf": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
